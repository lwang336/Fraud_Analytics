{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Prep_Feature_Selection_Algorithm_Part_I.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rOG9auc513f9",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKZSblZAnUQT",
        "colab_type": "code",
        "outputId": "f48df6d7-5c3f-4dc1-bf24-ad83e3c29e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMbr3JmnXhnH",
        "colab_type": "text"
      },
      "source": [
        "#### Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbd2_NS5nQFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.stats as sps\n",
        "from scipy.stats import zscore"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ksgC98zb1-Us",
        "colab": {}
      },
      "source": [
        "finaldf=pd.read_csv('/content/drive/Shared drives/DSO562 Fraud Project/Project2/candidates_v2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZUQ-LQ_2tEE",
        "colab": {}
      },
      "source": [
        "mydata=finaldf[finaldf['date']>\"2016-01-14\"].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_gN9euwnQFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydatacopy=mydata.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF3PuuGonQFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata=mydata.drop(columns=['Unnamed: 0','record','date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1E-_34-nQFl",
        "colab_type": "code",
        "outputId": "80a368fc-69ad-4e96-b6c9-3ef368d94319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "mydata['address_days_since_last_seen']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38511       0.0\n",
              "38512       0.0\n",
              "38513       0.0\n",
              "38514       0.0\n",
              "38515       0.0\n",
              "          ...  \n",
              "999995      0.0\n",
              "999996      0.0\n",
              "999997      0.0\n",
              "999998      0.0\n",
              "999999    319.0\n",
              "Name: address_days_since_last_seen, Length: 961489, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8yJnVZinQFo",
        "colab_type": "code",
        "outputId": "dcf85612-8507-4e6b-d21f-84f9e72df281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "mydata['fulladdress_days_since_last_seen']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38511       0.0\n",
              "38512       0.0\n",
              "38513       0.0\n",
              "38514       0.0\n",
              "38515       0.0\n",
              "          ...  \n",
              "999995      0.0\n",
              "999996      0.0\n",
              "999997      0.0\n",
              "999998      0.0\n",
              "999999    319.0\n",
              "Name: fulladdress_days_since_last_seen, Length: 961489, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JM6XfhSJ2tgD",
        "colab": {}
      },
      "source": [
        "mydata['random']=np.random.uniform(size = len(mydata))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8-MKDXL621Vr",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import scipy.stats as sps\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IHAwI4DokYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_data = scaler.fit_transform(mydata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ym8wO9jnQFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = mydata.columns\n",
        "scaled_data=pd.DataFrame(scaled_data, columns=names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNVkohVhnQF0",
        "colab_type": "code",
        "outputId": "334df1fb-aca0-4fb8-d078-63750e97f322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "scaled_data['ssnfname_nunique3_ssn'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    961489.0\n",
              "mean          0.0\n",
              "std           0.0\n",
              "min           0.0\n",
              "25%           0.0\n",
              "50%           0.0\n",
              "75%           0.0\n",
              "max           0.0\n",
              "Name: ssnfname_nunique3_ssn, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CENhe-XTnQF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zmydata=scaled_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62DNoJRdnQF4",
        "colab_type": "code",
        "outputId": "a2970659-5a75-4a6d-b19a-793f9e80a47a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "zmydata.isna()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fraud_label</th>\n",
              "      <th>ssn_count0_date</th>\n",
              "      <th>ssn_count1_date</th>\n",
              "      <th>ssn_count3_date</th>\n",
              "      <th>ssn_count7_date</th>\n",
              "      <th>ssn_count14_date</th>\n",
              "      <th>ssn_count30_date</th>\n",
              "      <th>ssn_count180_date</th>\n",
              "      <th>address_count0_date</th>\n",
              "      <th>address_count1_date</th>\n",
              "      <th>address_count3_date</th>\n",
              "      <th>address_count7_date</th>\n",
              "      <th>address_count14_date</th>\n",
              "      <th>address_count30_date</th>\n",
              "      <th>address_count180_date</th>\n",
              "      <th>dob_count0_date</th>\n",
              "      <th>dob_count1_date</th>\n",
              "      <th>dob_count3_date</th>\n",
              "      <th>dob_count7_date</th>\n",
              "      <th>dob_count14_date</th>\n",
              "      <th>dob_count30_date</th>\n",
              "      <th>dob_count180_date</th>\n",
              "      <th>homephone_count0_date</th>\n",
              "      <th>homephone_count1_date</th>\n",
              "      <th>homephone_count3_date</th>\n",
              "      <th>homephone_count7_date</th>\n",
              "      <th>homephone_count14_date</th>\n",
              "      <th>homephone_count30_date</th>\n",
              "      <th>homephone_count180_date</th>\n",
              "      <th>namedob_count0_date</th>\n",
              "      <th>namedob_count1_date</th>\n",
              "      <th>namedob_count3_date</th>\n",
              "      <th>namedob_count7_date</th>\n",
              "      <th>namedob_count14_date</th>\n",
              "      <th>namedob_count30_date</th>\n",
              "      <th>namedob_count180_date</th>\n",
              "      <th>fulladdress_count0_date</th>\n",
              "      <th>fulladdress_count1_date</th>\n",
              "      <th>fulladdress_count3_date</th>\n",
              "      <th>fulladdress_count7_date</th>\n",
              "      <th>...</th>\n",
              "      <th>dob_nunique1_ssn</th>\n",
              "      <th>dob_nunique1_homephone</th>\n",
              "      <th>dob_nunique1_ssnfname</th>\n",
              "      <th>dob_nunique1_fulladdress</th>\n",
              "      <th>dob_nunique3_ssn</th>\n",
              "      <th>dob_nunique3_homephone</th>\n",
              "      <th>dob_nunique3_ssnfname</th>\n",
              "      <th>dob_nunique3_fulladdress</th>\n",
              "      <th>fulladdress_nunique1_ssn</th>\n",
              "      <th>fulladdress_nunique1_homephone</th>\n",
              "      <th>fulladdress_nunique1_ssnfname</th>\n",
              "      <th>fulladdress_nunique1_dob</th>\n",
              "      <th>fulladdress_nunique3_ssn</th>\n",
              "      <th>fulladdress_nunique3_homephone</th>\n",
              "      <th>fulladdress_nunique3_ssnfname</th>\n",
              "      <th>fulladdress_nunique3_dob</th>\n",
              "      <th>ssn_days_since_last_seen</th>\n",
              "      <th>address_days_since_last_seen</th>\n",
              "      <th>dob_days_since_last_seen</th>\n",
              "      <th>homephone_days_since_last_seen</th>\n",
              "      <th>namedob_days_since_last_seen</th>\n",
              "      <th>fulladdress_days_since_last_seen</th>\n",
              "      <th>ssnfname_days_since_last_seen</th>\n",
              "      <th>ssnlname_days_since_last_seen</th>\n",
              "      <th>ssnfullname_days_since_last_seen</th>\n",
              "      <th>ssnaddress_days_since_last_seen</th>\n",
              "      <th>ssnzip5_days_since_last_seen</th>\n",
              "      <th>ssndob_days_since_last_seen</th>\n",
              "      <th>ssnhomephone_days_since_last_seen</th>\n",
              "      <th>ssnnamedob_days_since_last_seen</th>\n",
              "      <th>ssnfulladdress_days_since_last_seen</th>\n",
              "      <th>namehomephone_days_since_last_seen</th>\n",
              "      <th>namefulladdress_days_since_last_seen</th>\n",
              "      <th>fulladdressdob_days_since_last_seen</th>\n",
              "      <th>fulladdresshomephone_days_since_last_seen</th>\n",
              "      <th>fulladdressnamedob_days_since_last_seen</th>\n",
              "      <th>dobhomephone_days_since_last_seen</th>\n",
              "      <th>homephonenamedob_days_since_last_seen</th>\n",
              "      <th>dayofweek_risk</th>\n",
              "      <th>random</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961484</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961485</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961486</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961487</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961488</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>961489 rows  307 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        fraud_label  ssn_count0_date  ...  dayofweek_risk  random\n",
              "0             False            False  ...           False   False\n",
              "1             False            False  ...           False   False\n",
              "2             False            False  ...           False   False\n",
              "3             False            False  ...           False   False\n",
              "4             False            False  ...           False   False\n",
              "...             ...              ...  ...             ...     ...\n",
              "961484        False            False  ...           False   False\n",
              "961485        False            False  ...           False   False\n",
              "961486        False            False  ...           False   False\n",
              "961487        False            False  ...           False   False\n",
              "961488        False            False  ...           False   False\n",
              "\n",
              "[961489 rows x 307 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EO9Q-drnQF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zmydata['date']=mydatacopy['date'].values\n",
        "zmydata['fraud_label']=mydata['fraud_label'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XwNGK1DnQF-",
        "colab_type": "code",
        "outputId": "b8d7b4b2-a422-4025-ef9a-f1f0bace4401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "zmydata['fraud_label'].sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_zHmuwgnQGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zmydatatest=zmydata[zmydata['date']>\"2016-10-31\"]\n",
        "zmydatatest=zmydatatest.drop(columns=['date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hm1jBy2nQGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zmydatatrain=zmydata[zmydata['date']<=\"2016-10-31\"]\n",
        "zmydatatrain=zmydatatrain.drop(columns=['date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xpAi0QVnQGF",
        "colab_type": "code",
        "outputId": "e7b8c216-882b-4b97-ee57-421063f58861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "zmydatatrain['ssnfname_nunique3_ssn'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    794996.0\n",
              "mean          0.0\n",
              "std           0.0\n",
              "min           0.0\n",
              "25%           0.0\n",
              "50%           0.0\n",
              "75%           0.0\n",
              "max           0.0\n",
              "Name: ssnfname_nunique3_ssn, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz-3Y6YinQGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "goodscopy=zmydatatrain[zmydatatrain['fraud_label']==0].copy()\n",
        "badscopy=zmydatatrain[zmydatatrain['fraud_label']==1].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHoSBsz1nQGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collist=zmydatatrain.columns.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2hzdMb3nQGM",
        "colab_type": "code",
        "outputId": "a3ea75ad-8683-404d-c201-0ac90b7538e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sps.ks_2samp(goodscopy['ssn_count0_date'],badscopy['ssn_count0_date'])[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10709290590090792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j2oG1hYZ24fJ",
        "colab": {}
      },
      "source": [
        "i=0\n",
        "KSFDR=[]\n",
        "for column in collist:\n",
        "    KSFDR.append(sps.ks_2samp(goodscopy[column],badscopy[column])[0])\n",
        "    i=i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpKVwYhsnQGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KSFDR=pd.DataFrame(KSFDR,columns=['ks'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjjFxqCnQGV",
        "colab_type": "code",
        "outputId": "178b3b35-e57b-48c2-84fb-2fce7f4ef694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "KSFDR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.107093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.148704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.172102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.193036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0.058663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>0.060210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>0.058460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>0.022088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>0.007633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows  1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           ks\n",
              "0    1.000000\n",
              "1    0.107093\n",
              "2    0.148704\n",
              "3    0.172102\n",
              "4    0.193036\n",
              "..        ...\n",
              "302  0.058663\n",
              "303  0.060210\n",
              "304  0.058460\n",
              "305  0.022088\n",
              "306  0.007633\n",
              "\n",
              "[307 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "V7YTWyzinQGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topRows = int(round(len(zmydatatrain)*0.03))\n",
        "j = 0\n",
        "numbads=sum(zmydatatrain['fraud_label']==1)\n",
        "temp0=pd.DataFrame()\n",
        "for column in zmydatatrain:\n",
        "    if column=='fraud_label':\n",
        "        temp0['fraud_label'] = zmydatatrain['fraud_label']\n",
        "        temp0['fraud_label2']=zmydatatrain['fraud_label']\n",
        "    else:\n",
        "        temp0 = zmydatatrain[[column,'fraud_label']].copy()\n",
        "    temp1 = temp0.sort_values(column,ascending=False).head(topRows).copy()\n",
        "    temp2 = temp0.sort_values(column,ascending=True).head(topRows).copy()\n",
        "    needed1 = temp1.loc[:,'fraud_label']\n",
        "    needed2 = temp2.loc[:,'fraud_label']\n",
        "    FDR1 = sum(needed1)/numbads\n",
        "    FDR2 = sum(needed2)/numbads\n",
        "    FDRate = np.maximum(FDR1,FDR2)\n",
        "    KSFDR.loc[j, 'FDR'] = FDRate\n",
        "    j = j +1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvIHJC8inQGa",
        "colab_type": "code",
        "outputId": "4e962471-a7de-4c72-b2ad-305e9ed420f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "KSFDR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ks</th>\n",
              "      <th>FDR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.107093</td>\n",
              "      <td>0.134947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.148704</td>\n",
              "      <td>0.175431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.172102</td>\n",
              "      <td>0.198328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.193036</td>\n",
              "      <td>0.218614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0.058663</td>\n",
              "      <td>0.082971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>0.060210</td>\n",
              "      <td>0.086627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>0.058460</td>\n",
              "      <td>0.083928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>0.022088</td>\n",
              "      <td>0.033780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>0.007633</td>\n",
              "      <td>0.030559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           ks       FDR\n",
              "0    1.000000  1.000000\n",
              "1    0.107093  0.134947\n",
              "2    0.148704  0.175431\n",
              "3    0.172102  0.198328\n",
              "4    0.193036  0.218614\n",
              "..        ...       ...\n",
              "302  0.058663  0.082971\n",
              "303  0.060210  0.086627\n",
              "304  0.058460  0.083928\n",
              "305  0.022088  0.033780\n",
              "306  0.007633  0.030559\n",
              "\n",
              "[307 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlCTbkO_nQGd",
        "colab_type": "code",
        "outputId": "ceccb433-eca9-4df2-ecf3-d3242b9eed46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "numbads"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11486"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I-aOzj7nQGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KSFDR['rank_ks'] = KSFDR['ks'].rank(ascending = True)\n",
        "KSFDR['rank_FDR'] = KSFDR['FDR'].rank(ascending = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-dNHg0snQGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KSFDR['average_rank'] = (KSFDR['rank_ks'] + KSFDR['rank_FDR']) / 2\n",
        "KSFDR.sort_values(by=['average_rank'], ascending=False, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDzWEQ4rnQGk",
        "colab_type": "code",
        "outputId": "b5686bc4-d7d5-44f9-a28c-6ad028e46bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "KSFDR\n",
        "newKSFDR=KSFDR.reset_index()\n",
        "newKSFDR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ks</th>\n",
              "      <th>FDR</th>\n",
              "      <th>rank_ks</th>\n",
              "      <th>rank_FDR</th>\n",
              "      <th>average_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>307.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>307.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>288</td>\n",
              "      <td>0.333210</td>\n",
              "      <td>0.358349</td>\n",
              "      <td>305.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>305.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>284</td>\n",
              "      <td>0.334096</td>\n",
              "      <td>0.355128</td>\n",
              "      <td>306.0</td>\n",
              "      <td>305.0</td>\n",
              "      <td>305.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41</td>\n",
              "      <td>0.332032</td>\n",
              "      <td>0.354954</td>\n",
              "      <td>303.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>303.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>0.332725</td>\n",
              "      <td>0.353300</td>\n",
              "      <td>304.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>303.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>249</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.033084</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>265</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.033258</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>4.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>244</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.033258</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>4.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>259</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.033084</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>263</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.033084</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index        ks       FDR  rank_ks  rank_FDR  average_rank\n",
              "0        0  1.000000  1.000000    307.0     307.0        307.00\n",
              "1      288  0.333210  0.358349    305.0     306.0        305.50\n",
              "2      284  0.334096  0.355128    306.0     305.0        305.50\n",
              "3       41  0.332032  0.354954    303.0     304.0        303.50\n",
              "4       13  0.332725  0.353300    304.0     303.0        303.50\n",
              "..     ...       ...       ...      ...       ...           ...\n",
              "302    249  0.000128  0.033084      8.0       3.0          5.50\n",
              "303    265  0.000103  0.033258      4.0       5.5          4.75\n",
              "304    244  0.000015  0.033258      3.0       5.5          4.25\n",
              "305    259 -0.000000  0.033084      1.5       3.0          2.25\n",
              "306    263 -0.000000  0.033084      1.5       3.0          2.25\n",
              "\n",
              "[307 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rE1Cyc8unQGn",
        "colab_type": "code",
        "outputId": "31317ac2-59dd-4663-d37e-4c163854ea77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "matchcolumn=pd.DataFrame(collist)\n",
        "matchcolumn=matchcolumn.reset_index()\n",
        "matchcolumn=matchcolumn.rename(columns={0: 'VariableName'})\n",
        "matchcolumn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>VariableName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>fraud_label</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ssn_count0_date</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ssn_count1_date</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ssn_count3_date</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ssn_count7_date</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>302</td>\n",
              "      <td>fulladdressnamedob_days_since_last_seen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>303</td>\n",
              "      <td>dobhomephone_days_since_last_seen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>304</td>\n",
              "      <td>homephonenamedob_days_since_last_seen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>305</td>\n",
              "      <td>dayofweek_risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>306</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                             VariableName\n",
              "0        0                              fraud_label\n",
              "1        1                          ssn_count0_date\n",
              "2        2                          ssn_count1_date\n",
              "3        3                          ssn_count3_date\n",
              "4        4                          ssn_count7_date\n",
              "..     ...                                      ...\n",
              "302    302  fulladdressnamedob_days_since_last_seen\n",
              "303    303        dobhomephone_days_since_last_seen\n",
              "304    304    homephonenamedob_days_since_last_seen\n",
              "305    305                           dayofweek_risk\n",
              "306    306                                   random\n",
              "\n",
              "[307 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "U9KyIcdCnQGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newKSFDR = pd.merge(matchcolumn, newKSFDR, left_on = ['index'], right_on = ['index'],how='right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-R59g0InQGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newKSFDR=newKSFDR.sort_values('average_rank',ascending=False)\n",
        "newKSFDR=newKSFDR.drop(columns=['index'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kps-85sNnQGu",
        "colab_type": "code",
        "outputId": "c994fc7b-bcd9-43a6-84a4-08d3f3d1bdca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "newKSFDR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VariableName</th>\n",
              "      <th>ks</th>\n",
              "      <th>FDR</th>\n",
              "      <th>rank_ks</th>\n",
              "      <th>rank_FDR</th>\n",
              "      <th>average_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fraud_label</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>307.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>307.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>fulladdress_days_since_last_seen</td>\n",
              "      <td>0.333210</td>\n",
              "      <td>0.358349</td>\n",
              "      <td>305.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>305.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>address_days_since_last_seen</td>\n",
              "      <td>0.334096</td>\n",
              "      <td>0.355128</td>\n",
              "      <td>306.0</td>\n",
              "      <td>305.0</td>\n",
              "      <td>305.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>fulladdress_count30_date</td>\n",
              "      <td>0.332032</td>\n",
              "      <td>0.354954</td>\n",
              "      <td>303.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>303.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>address_count30_date</td>\n",
              "      <td>0.332725</td>\n",
              "      <td>0.353300</td>\n",
              "      <td>304.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>303.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>ssn_nunique3_dob</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.033084</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>ssnfname_nunique3_dob</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.033258</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>4.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>ssn_nunique1_ssnfname</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.033258</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>4.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>ssnfname_nunique1_ssn</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.033084</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>ssnfname_nunique3_ssn</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.033084</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         VariableName        ks  ...  rank_FDR  average_rank\n",
              "0                         fraud_label  1.000000  ...     307.0        307.00\n",
              "288  fulladdress_days_since_last_seen  0.333210  ...     306.0        305.50\n",
              "284      address_days_since_last_seen  0.334096  ...     305.0        305.50\n",
              "41           fulladdress_count30_date  0.332032  ...     304.0        303.50\n",
              "13               address_count30_date  0.332725  ...     303.0        303.50\n",
              "..                                ...       ...  ...       ...           ...\n",
              "249                  ssn_nunique3_dob  0.000128  ...       3.0          5.50\n",
              "265             ssnfname_nunique3_dob  0.000103  ...       5.5          4.75\n",
              "244             ssn_nunique1_ssnfname  0.000015  ...       5.5          4.25\n",
              "259             ssnfname_nunique1_ssn -0.000000  ...       3.0          2.25\n",
              "263             ssnfname_nunique3_ssn -0.000000  ...       3.0          2.25\n",
              "\n",
              "[307 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_P3EeajZnQGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newKSFDR.to_csv('homework6_0302.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRXx_rM_nQGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vars_keep=newKSFDR['VariableName'][1:55].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-C_pllqdnQG1",
        "colab_type": "code",
        "outputId": "f1979086-a5f4-4101-f109-a501027dbcb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "zmydatatrain[vars_keep]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fulladdress_days_since_last_seen</th>\n",
              "      <th>address_days_since_last_seen</th>\n",
              "      <th>fulladdress_count30_date</th>\n",
              "      <th>address_count30_date</th>\n",
              "      <th>address_count14_date</th>\n",
              "      <th>address_count180_date</th>\n",
              "      <th>fulladdress_count14_date</th>\n",
              "      <th>fulladdress_count180_date</th>\n",
              "      <th>address_count7_date</th>\n",
              "      <th>fulladdress_count7_date</th>\n",
              "      <th>fulladdress_count3_date</th>\n",
              "      <th>address_count3_date</th>\n",
              "      <th>fulladdress_nunique3_ssn</th>\n",
              "      <th>fulladdress_nunique3_ssnfname</th>\n",
              "      <th>fulladdress_nunique3_dob</th>\n",
              "      <th>address_count1_date</th>\n",
              "      <th>fulladdress_count1_date</th>\n",
              "      <th>fulladdress_nunique1_dob</th>\n",
              "      <th>fulladdress_nunique1_ssn</th>\n",
              "      <th>fulladdress_nunique1_ssnfname</th>\n",
              "      <th>fulladdresshomephone_days_since_last_seen</th>\n",
              "      <th>fulladdresshomephone_count30_date</th>\n",
              "      <th>ssndob_days_since_last_seen</th>\n",
              "      <th>ssndob_count30_date</th>\n",
              "      <th>namedob_count30_date</th>\n",
              "      <th>namedob_days_since_last_seen</th>\n",
              "      <th>ssn_days_since_last_seen</th>\n",
              "      <th>ssn_count30_date</th>\n",
              "      <th>ssnfname_days_since_last_seen</th>\n",
              "      <th>ssnnamedob_days_since_last_seen</th>\n",
              "      <th>ssnlname_days_since_last_seen</th>\n",
              "      <th>ssnnamedob_count30_date</th>\n",
              "      <th>ssnfname_count30_date</th>\n",
              "      <th>ssnlname_count30_date</th>\n",
              "      <th>ssnfullname_days_since_last_seen</th>\n",
              "      <th>ssnfullname_count30_date</th>\n",
              "      <th>ssndob_count180_date</th>\n",
              "      <th>namedob_count180_date</th>\n",
              "      <th>ssn_count180_date</th>\n",
              "      <th>fulladdresshomephone_count180_date</th>\n",
              "      <th>fulladdresshomephone_count14_date</th>\n",
              "      <th>ssnlname_count180_date</th>\n",
              "      <th>ssnfname_count180_date</th>\n",
              "      <th>ssnnamedob_count180_date</th>\n",
              "      <th>ssnfullname_count180_date</th>\n",
              "      <th>namedob_count14_date</th>\n",
              "      <th>ssndob_count14_date</th>\n",
              "      <th>ssn_count14_date</th>\n",
              "      <th>ssnnamedob_count14_date</th>\n",
              "      <th>ssnfname_count14_date</th>\n",
              "      <th>ssnlname_count14_date</th>\n",
              "      <th>ssnfullname_count14_date</th>\n",
              "      <th>address_1_count_address_14_count_Ave</th>\n",
              "      <th>fulladdress_1_count_fulladdress_14_count_Ave</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794991</th>\n",
              "      <td>2.862299</td>\n",
              "      <td>2.658984</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>0.644301</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>1.007958</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>3.074655</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>3.148812</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>3.140509</td>\n",
              "      <td>2.953143</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>2.972643</td>\n",
              "      <td>3.156585</td>\n",
              "      <td>2.973034</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>2.978121</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>1.259643</td>\n",
              "      <td>1.246107</td>\n",
              "      <td>0.923321</td>\n",
              "      <td>1.219699</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>1.221131</td>\n",
              "      <td>1.220850</td>\n",
              "      <td>1.262812</td>\n",
              "      <td>1.223069</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794992</th>\n",
              "      <td>1.721358</td>\n",
              "      <td>1.579932</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>0.644301</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>1.007958</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>1.869351</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>1.921002</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>1.915180</td>\n",
              "      <td>1.784372</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>1.797909</td>\n",
              "      <td>1.926374</td>\n",
              "      <td>1.798186</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>1.801731</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>1.259643</td>\n",
              "      <td>1.246107</td>\n",
              "      <td>0.923321</td>\n",
              "      <td>1.219699</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>1.221131</td>\n",
              "      <td>1.220850</td>\n",
              "      <td>1.262812</td>\n",
              "      <td>1.223069</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794993</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794994</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794995</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>794996 rows  54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        fulladdress_days_since_last_seen  ...  fulladdress_1_count_fulladdress_14_count_Ave\n",
              "0                              -0.411706  ...                                      0.125036\n",
              "1                              -0.411706  ...                                      0.125036\n",
              "2                              -0.411706  ...                                      0.125036\n",
              "3                              -0.411706  ...                                      0.125036\n",
              "4                              -0.411706  ...                                      0.125036\n",
              "...                                  ...  ...                                           ...\n",
              "794991                          2.862299  ...                                      0.125036\n",
              "794992                          1.721358  ...                                      0.125036\n",
              "794993                         -0.411706  ...                                      0.125036\n",
              "794994                         -0.411706  ...                                      0.125036\n",
              "794995                         -0.411706  ...                                      0.125036\n",
              "\n",
              "[794996 rows x 54 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmyXgtVCnQG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vars_keep=zmydatatrain[vars_keep]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFTHrrSdnQG5",
        "colab_type": "code",
        "outputId": "e34ad63b-b2b8-495f-84cd-bb355a6dd58f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(vars_keep)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "794996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xMFTyQ1nQG7",
        "colab_type": "text"
      },
      "source": [
        "#### Wrappers are highly sensitive to change of data: fluctuation / variation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xwS5D4XvnQG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "model = LogisticRegression()\n",
        "rfecv = RFECV(estimator=model, step=1, cv=2, verbose=3, n_jobs=-1, scoring='roc_auc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uqBJgrgnQG-",
        "colab_type": "code",
        "outputId": "5ec97cf8-b722-4ac8-c4be-0fc556af2666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "Y = np.array(zmydatatrain['fraud_label']).reshape(-1, 1)\n",
        "Y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(794996, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh_Fko42nQHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Capping some variables "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e811eFu5oA7j",
        "colab_type": "code",
        "outputId": "a7839ccf-427f-4d98-c067-a6e398b6a241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "vars_keep"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fulladdress_days_since_last_seen</th>\n",
              "      <th>address_days_since_last_seen</th>\n",
              "      <th>fulladdress_count30_date</th>\n",
              "      <th>address_count30_date</th>\n",
              "      <th>address_count14_date</th>\n",
              "      <th>address_count180_date</th>\n",
              "      <th>fulladdress_count14_date</th>\n",
              "      <th>fulladdress_count180_date</th>\n",
              "      <th>address_count7_date</th>\n",
              "      <th>fulladdress_count7_date</th>\n",
              "      <th>fulladdress_count3_date</th>\n",
              "      <th>address_count3_date</th>\n",
              "      <th>fulladdress_nunique3_ssn</th>\n",
              "      <th>fulladdress_nunique3_ssnfname</th>\n",
              "      <th>fulladdress_nunique3_dob</th>\n",
              "      <th>address_count1_date</th>\n",
              "      <th>fulladdress_count1_date</th>\n",
              "      <th>fulladdress_nunique1_dob</th>\n",
              "      <th>fulladdress_nunique1_ssn</th>\n",
              "      <th>fulladdress_nunique1_ssnfname</th>\n",
              "      <th>fulladdresshomephone_days_since_last_seen</th>\n",
              "      <th>fulladdresshomephone_count30_date</th>\n",
              "      <th>ssndob_days_since_last_seen</th>\n",
              "      <th>ssndob_count30_date</th>\n",
              "      <th>namedob_count30_date</th>\n",
              "      <th>namedob_days_since_last_seen</th>\n",
              "      <th>ssn_days_since_last_seen</th>\n",
              "      <th>ssn_count30_date</th>\n",
              "      <th>ssnfname_days_since_last_seen</th>\n",
              "      <th>ssnnamedob_days_since_last_seen</th>\n",
              "      <th>ssnlname_days_since_last_seen</th>\n",
              "      <th>ssnnamedob_count30_date</th>\n",
              "      <th>ssnfname_count30_date</th>\n",
              "      <th>ssnlname_count30_date</th>\n",
              "      <th>ssnfullname_days_since_last_seen</th>\n",
              "      <th>ssnfullname_count30_date</th>\n",
              "      <th>ssndob_count180_date</th>\n",
              "      <th>namedob_count180_date</th>\n",
              "      <th>ssn_count180_date</th>\n",
              "      <th>fulladdresshomephone_count180_date</th>\n",
              "      <th>fulladdresshomephone_count14_date</th>\n",
              "      <th>ssnlname_count180_date</th>\n",
              "      <th>ssnfname_count180_date</th>\n",
              "      <th>ssnnamedob_count180_date</th>\n",
              "      <th>ssnfullname_count180_date</th>\n",
              "      <th>namedob_count14_date</th>\n",
              "      <th>ssndob_count14_date</th>\n",
              "      <th>ssn_count14_date</th>\n",
              "      <th>ssnnamedob_count14_date</th>\n",
              "      <th>ssnfname_count14_date</th>\n",
              "      <th>ssnlname_count14_date</th>\n",
              "      <th>ssnfullname_count14_date</th>\n",
              "      <th>address_1_count_address_14_count_Ave</th>\n",
              "      <th>fulladdress_1_count_fulladdress_14_count_Ave</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794991</th>\n",
              "      <td>2.862299</td>\n",
              "      <td>2.658984</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>0.644301</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>1.007958</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>3.074655</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>3.148812</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>3.140509</td>\n",
              "      <td>2.953143</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>2.972643</td>\n",
              "      <td>3.156585</td>\n",
              "      <td>2.973034</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>2.978121</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>1.259643</td>\n",
              "      <td>1.246107</td>\n",
              "      <td>0.923321</td>\n",
              "      <td>1.219699</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>1.221131</td>\n",
              "      <td>1.220850</td>\n",
              "      <td>1.262812</td>\n",
              "      <td>1.223069</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794992</th>\n",
              "      <td>1.721358</td>\n",
              "      <td>1.579932</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>0.644301</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>1.007958</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>1.869351</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>1.921002</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>1.915180</td>\n",
              "      <td>1.784372</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>1.797909</td>\n",
              "      <td>1.926374</td>\n",
              "      <td>1.798186</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>1.801731</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>1.259643</td>\n",
              "      <td>1.246107</td>\n",
              "      <td>0.923321</td>\n",
              "      <td>1.219699</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>1.221131</td>\n",
              "      <td>1.220850</td>\n",
              "      <td>1.262812</td>\n",
              "      <td>1.223069</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794993</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794994</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794995</th>\n",
              "      <td>-0.411706</td>\n",
              "      <td>-0.437425</td>\n",
              "      <td>-0.103392</td>\n",
              "      <td>-0.119479</td>\n",
              "      <td>-0.089339</td>\n",
              "      <td>-0.214284</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>-0.227749</td>\n",
              "      <td>-0.073005</td>\n",
              "      <td>-0.067413</td>\n",
              "      <td>-0.058171</td>\n",
              "      <td>-0.061071</td>\n",
              "      <td>-0.052073</td>\n",
              "      <td>-0.052086</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.051332</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.047263</td>\n",
              "      <td>-0.047001</td>\n",
              "      <td>-0.047011</td>\n",
              "      <td>-0.384043</td>\n",
              "      <td>-0.096485</td>\n",
              "      <td>-0.374468</td>\n",
              "      <td>-0.09434</td>\n",
              "      <td>-0.094632</td>\n",
              "      <td>-0.375653</td>\n",
              "      <td>-0.400721</td>\n",
              "      <td>-0.100589</td>\n",
              "      <td>-0.398333</td>\n",
              "      <td>-0.373585</td>\n",
              "      <td>-0.398269</td>\n",
              "      <td>-0.094045</td>\n",
              "      <td>-0.099596</td>\n",
              "      <td>-0.099584</td>\n",
              "      <td>-0.397608</td>\n",
              "      <td>-0.099366</td>\n",
              "      <td>-0.218006</td>\n",
              "      <td>-0.217501</td>\n",
              "      <td>-0.189519</td>\n",
              "      <td>-0.222642</td>\n",
              "      <td>-0.070856</td>\n",
              "      <td>-0.234407</td>\n",
              "      <td>-0.234458</td>\n",
              "      <td>-0.217328</td>\n",
              "      <td>-0.233941</td>\n",
              "      <td>-0.069169</td>\n",
              "      <td>-0.068978</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.068841</td>\n",
              "      <td>-0.071707</td>\n",
              "      <td>-0.07167</td>\n",
              "      <td>-0.071577</td>\n",
              "      <td>0.141748</td>\n",
              "      <td>0.125036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>794996 rows  54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        fulladdress_days_since_last_seen  ...  fulladdress_1_count_fulladdress_14_count_Ave\n",
              "0                              -0.411706  ...                                      0.125036\n",
              "1                              -0.411706  ...                                      0.125036\n",
              "2                              -0.411706  ...                                      0.125036\n",
              "3                              -0.411706  ...                                      0.125036\n",
              "4                              -0.411706  ...                                      0.125036\n",
              "...                                  ...  ...                                           ...\n",
              "794991                          2.862299  ...                                      0.125036\n",
              "794992                          1.721358  ...                                      0.125036\n",
              "794993                         -0.411706  ...                                      0.125036\n",
              "794994                         -0.411706  ...                                      0.125036\n",
              "794995                         -0.411706  ...                                      0.125036\n",
              "\n",
              "[794996 rows x 54 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLIjcwqpndch",
        "colab_type": "code",
        "outputId": "6fbf79f5-e260-4eb6-f0e9-9ab2738aaddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rfecv.fit(vars_keep,Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 54 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 53 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 52 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 51 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 50 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 49 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 48 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 47 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 46 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 45 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 44 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 43 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 42 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 41 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 40 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 39 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 38 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 37 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 36 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 35 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 34 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 33 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 32 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 31 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 30 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 29 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 28 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 27 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 26 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 25 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 24 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 23 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 22 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 21 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 20 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFECV(cv=2,\n",
              "      estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                   fit_intercept=True, intercept_scaling=1,\n",
              "                                   l1_ratio=None, max_iter=100,\n",
              "                                   multi_class='auto', n_jobs=None,\n",
              "                                   penalty='l2', random_state=None,\n",
              "                                   solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                   warm_start=False),\n",
              "      min_features_to_select=1, n_jobs=-1, scoring='roc_auc', step=1,\n",
              "      verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVaOO9qnnQHG",
        "colab_type": "code",
        "outputId": "6dc51971-6294-4483-9184-4018ba74538f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        }
      },
      "source": [
        "var_selected = pd.DataFrame(sorted(zip(map(lambda x: round(x), rfecv.ranking_), vars_keep.columns)),\n",
        "                            columns = ['ranking', 'variable'])\n",
        "print(var_selected)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    ranking                                      variable\n",
            "0         1                       fulladdress_count1_date\n",
            "1         1                      fulladdress_count30_date\n",
            "2         1              fulladdress_days_since_last_seen\n",
            "3         1                      fulladdress_nunique1_dob\n",
            "4         1             fulladdresshomephone_count30_date\n",
            "5         1     fulladdresshomephone_days_since_last_seen\n",
            "6         1                          namedob_count14_date\n",
            "7         1                          namedob_count30_date\n",
            "8         1                  namedob_days_since_last_seen\n",
            "9         1                      ssn_days_since_last_seen\n",
            "10        1                           ssndob_count30_date\n",
            "11        1                   ssndob_days_since_last_seen\n",
            "12        1                 ssnfname_days_since_last_seen\n",
            "13        1                      ssnfullname_count30_date\n",
            "14        1              ssnfullname_days_since_last_seen\n",
            "15        1                         ssnlname_count30_date\n",
            "16        1                 ssnlname_days_since_last_seen\n",
            "17        1                       ssnnamedob_count30_date\n",
            "18        1               ssnnamedob_days_since_last_seen\n",
            "19        2                        ssnlname_count180_date\n",
            "20        3             fulladdresshomephone_count14_date\n",
            "21        4                      fulladdress_nunique3_ssn\n",
            "22        5                  address_days_since_last_seen\n",
            "23        6                         ssnfname_count14_date\n",
            "24        7                         ssnlname_count14_date\n",
            "25        8                         ssnfname_count30_date\n",
            "26        9                     ssnfullname_count180_date\n",
            "27       10                        ssnfname_count180_date\n",
            "28       11                         namedob_count180_date\n",
            "29       12                      ssnnamedob_count180_date\n",
            "30       13                     fulladdress_count180_date\n",
            "31       14                          address_count30_date\n",
            "32       15                      fulladdress_nunique3_dob\n",
            "33       16                           address_count3_date\n",
            "34       17                              ssn_count14_date\n",
            "35       18                              ssn_count30_date\n",
            "36       19                       fulladdress_count7_date\n",
            "37       20                       ssnnamedob_count14_date\n",
            "38       21                       fulladdress_count3_date\n",
            "39       22                           address_count1_date\n",
            "40       23                           address_count7_date\n",
            "41       24                      fulladdress_count14_date\n",
            "42       25          address_1_count_address_14_count_Ave\n",
            "43       26                         address_count180_date\n",
            "44       27                 fulladdress_nunique3_ssnfname\n",
            "45       28            fulladdresshomephone_count180_date\n",
            "46       29                      ssnfullname_count14_date\n",
            "47       30                          ssndob_count180_date\n",
            "48       31                             ssn_count180_date\n",
            "49       32                      fulladdress_nunique1_ssn\n",
            "50       33  fulladdress_1_count_fulladdress_14_count_Ave\n",
            "51       34                 fulladdress_nunique1_ssnfname\n",
            "52       35                          address_count14_date\n",
            "53       36                           ssndob_count14_date\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ItITNEVwYLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var_selected.to_csv('var_80.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDq9-K8WnQHI",
        "colab_type": "code",
        "outputId": "3cb43b3a-0063-458c-f045-ee7e7e3f2114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "var_selected.to_csv('/content/drive/My Drive/Spring 2020/DSO 562 - Fraud Analytics/Project 2/selected_variables.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-455-b6228369ca61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvar_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Spring 2020/DSO 562 - Fraud Analytics/Project 2/selected_variables.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'var_selected' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_Y30DYQmHLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var_selected=pd.read_csv(('/content/drive/My Drive/Spring 2020/DSO 562 - Fraud Analytics/Project 2/selected_variables.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2ammTVlnQHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZiIE3G6nQHP",
        "colab_type": "code",
        "outputId": "98a068f8-f1ee-416b-b116-a6fad6720db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plt.figure()\n",
        "plt.xlabel('Number of features selected')\n",
        "plt.ylabel('Cross validation score (AUC)')\n",
        "plt.plot(range(1,len(rfecv.grid_scores_)+1),rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5xcdX3/8dd7Zy/Z3K9QSAiJEERQ\nQFwRAX/iBaRqwVrFoIhWK21VvBUq/rQotLZWqtL+4GdFpWK98FOKGm0UULkogiThIiRIjCFAAjXJ\n5kJ2kuzszHx+f5wzyWSZ7ExgJ7Mz834+HvPYOd8558znbDbnc873e77fryICMzOz4ToaHYCZmY1N\nThBmZlaRE4SZmVXkBGFmZhU5QZiZWUWdjQ5gtMycOTPmzZvX6DDMzJrKsmXLNkbErEqftUyCmDdv\nHkuXLm10GGZmTUXSo3v7zFVMZmZWkROEmZlV5ARhZmYVOUGYmVlFThBmZlaRE4SZmVXkBGFmZhW1\nTD8Ia179A4Pcv3YLqzdkyReDYgTFYlAoQiGC7oyY3NvF5HFdTOntYnJvJ5PHdSGJfLFIvhAMFYrk\ni0EEHDx1HAdN6SXToUYfmllTc4Kw/WrnUIEH1m3lvse2cN/aLdz/+BbWbt4x6t/TnengkOm9zJsx\ngUNnTODYQ6Zw5rEHIzlpmNXKCcJGRURUPPn2Dwyy7NHNLH10M0vXbOKBdVsZKiSTVM2e2stxh0zl\nvJceyrFzpnLEgZPo7uwg0yE6pPQn5ApFtu3M89SOIbbuGOKp9H0AnR2is0N0ZTrozIhiwBNbdrCm\nP8ujG7ezpj/Lnav7ueaOAj97aD2ffdMxjOvK7OffjllzcoKwZ+2TP3iQa+98NDlZZ0RXR3KyznSI\njQM5ILmif8GcKbzrlPn0HTqd4w6ZyqxJPTXtv6czQ8/EDDMn1rb+cBHBF2/7PZff+DCPbMxy9Xkv\n4qApvc9oX2btxAnCnpVlj27m2jsf5bSjDmTBARPJF9P2gEKQLxY5ZPp4XjxvOi+YPaVhV+6SeO+p\nh3PEAZP44HX3cuaVd/Clt7+I4+dOa0g8Zs1CrTIndV9fX3iwvv0rInjjF3/Fus07uPWiUxnfPfav\nN1b+YRt/ce1S/uepnXzmjS/gjcfPaWg8EUE2V2DrjiG2D+bZniuwPVdgx1DyPpcv0iHRkVa3dSj5\nOVQIduQKbM/l2T5UYEcueU0a18WsST17vGZM6Kans6Om9pdCMdi2c4jN24fYvD3H1tLPHUMM5ovk\nC0WG0uSfXAQkDwYE6c8IApg+oZuXLZjFcYdM9cMCY5ykZRHRV+mzsf8/2sasH/3mSe59bAuffdMx\nTZEcAI44cBI/eN/JvPeb9/CR79zPt+9+jEyHKBYhXyxSCCgUi+nJDkqXT6U2lvHdGcZ3Z5jQ3cmE\nnk4m9GToznSQLwa5QpGhfJGhspNoaR/JdVhQDNi2c4gt25OT8NYduV1tMs+GBOM6M+wYKlT8vEMw\nrivDuK4MvV0Zero6yEjszBfYOVRkZ67Aznyh5lgyadtPqb1IApHcrUnw1I4hrvjp75jS28XLFszk\n5UfM4uVHzOKAyeOetq+I4KkdedZt2cETW3bwxNYdrNuygw3bBpNfnkCUfwfD2qmSVylJFYpBIX0S\nLgJ6uzNMGtfJxJ5OJqY/ezozbM/lyeYKZAfzZAfzDAzm2bYzz9YdQ2zdnrR3bdmRJMehQuxKfknM\nyc+uTNL+tfslxnVlmDGhmxkTu5kxsYeZE3uYObGbDomNA4P0D+Tozw6ycSBH/8AgxUj209mRbN+Z\n6djVrpbp0K7PMhnRnX5Hd2cH3ZlM+lPMmTaes198yD7/3VTjOwh7RnYOFXjV525jSm8XP7zglKa7\nShwqFPncTSu5+5H+5D9ferLLdOxuHE8kJyZITgo7hwoMDOaTk8tggWwuTy5f3HWC6M6Irs6OtPG8\nY9e2Sq/8JZjY08m08d1MHd/F1PHdTO3tYur4LsZ3dzK+O0Nvd2bX++5MR/LYb3p1XkxPgF0Z7bFe\n6Q4hly/Snx1kw7bdr/5sjh25AjuHkiSwI1dkZ75AsRhpssgwrquD3jSBTOzpZNqELqb27hljT1cH\nnR3JsXVU+ffeun2IX6zawG0Pb+C2lRtYv20QgPHdmV2/y5JCBLl8cY/tuzMdzJrUg7R73dK5qhjs\nSgDFCArF5Pci2HWnVZ64duSSf7PiCKc6CSZ2JwlkSvrvMaV396unM7NrvfIjL1WpDhV2XyBsHyqw\nKU0C/QM5Nm3P7XG8U8d3pQkkubvrzHSkd2a7LyyGCslx7XHHVvqufPJduXz6KhQ5fu5UbnjvySP+\nm+z92Bt0ByHpDOBfgQzwlYj4zLDPvwC8Il0cDxwQEVPTz+YCXwEOIbmOeG1ErKlnvFa7/7hjDeu2\n7ODyNx3TdMkBoCvTwcV/fGSjwxh13Z0dHDSlt+GN8FPGd/H6Yw7m9cccTESw4smnuH3lRjZlB3et\nU6ryEjBrUg8HT+3l4Km9zJ7ay4wJ3VWT0L6ICHYMFRjYmWfbYJ6dQwXGdyd3gBN7OuntytTtEehC\nMdiUzVGMYPqEbroyo9s/OdIkWQ91SxCSMsBVwGnAWmCJpEURsaK0TkR8uGz9C4AXlu3i68CnI+Jm\nSROBPS8xrGE2Dgxy1S2rePXzDuCkw2c2Ohwb4yRx9MFTOPrgKQ2NIbnb6uSA/fzdmQ7V/MTeMyEl\nTw/WQz2H2jgBWBURqyMiB1wHnDXC+ucA3waQdBTQGRE3A0TEQERsr2Ostg+u+OlKdg4V+Nhrn9fo\nUMysjuqZIGYDj5ctr03LnkbSocB84Odp0RHAFkk3SLpX0uXpHcnw7c6XtFTS0g0bNoxy+FbJyj9s\n41u/foxzTzyUw2ZNbHQ4ZlZHY2WwvoXA9RFRegSjE3gZcCHwYuA5wDuHbxQRV0dEX0T0zZpVcc5t\nG2X/uPghJvR08oFXLWh0KGZWZ/VspF5H0sBcMictq2Qh8L6y5bXAfRGxGkDS94ETga/WIc5R8bfX\n38/tKzfS3dlBT2cHPV0ddGc6mNDTyV+//LCmrqvfOVTgztX93LziD9z68AY+/trnMX1Cd6PDMrM6\nq2eCWAIskDSfJDEsBN46fCVJRwLTgDuHbTtV0qyI2AC8EhjTz7DevnIjvd0Zjp0zhcF8kcH0EbTV\nG7Kcd83dXHbW83nrS+Y2OsyaRARr+rdz28PrueXhDdy1up/BfJFxXR2ceezBnHfSoY0O0cz2g7ol\niIjIS3o/cCPJY67XRMRySZcBSyNiUbrqQuC6KOuQEREFSRcCP1Py7Nky4Mv1inU0ZAfz/PEL/ohP\n/snRe5Rv2znEBd++l//9vQdYtX6Aj7/ueWPmsdCIpCfso/1ZHlz3FA+u28ryJ55i+RNbeWpnHoDn\nzJzAW18yl1OfewAvmT/dA92ZtZG69oOIiMXA4mFllwxb/tRetr0ZOKZuwY2iZLiEPBN7nv7rnDSu\ni6+c18enFz/ENXc8wpr+LP+68DgmjeuquJ/tuQKFCAqF3b1B88Vg48Agazfv4PFN25Ofm7fz5Jad\nDBWLu7r7lvf6zRd3b1tMlwvpq/x9uZ7ODo48aDJ/cuzBPH/2FE4+bCZzZ4wf7V+XmTWJ5hgfYYzb\nMVSgGDChQoIA6Mx08Mk/OZrDZk3kk4uW86Yv3slX3tFHoRg8sG4rDz6xlQfXbeXBdU+xdcdQ1e+b\n0tvFnGm9zJ0xnp7O5DmD8k5HwK5hEPbsHZx028+kvWFL5bOn9vL82VM4bNYEOke5E4+ZNS8niFEw\nMJhUx+wtQZSce+KhzJsxgb/+5jJe9tlbdpV3Zzp47h9N4rUvOIhDZ4x/+sldYvqEbuZMG8+c6b1M\nrnD3YWY22pwgRkF2MHk6d2JP9fr5UxbM5PvvO5nrl63l0Onjef7sKbsmyjEzG0ucIEZBtnQHUeOI\npofNmshHz2i9cYDMrLX4snUUlKqYKjVSm5k1KyeIUTCws7Y2CDOzZuIEMQqyOScIM2s9ThCjwFVM\nZtaKnCBGwa5G6hqeYjIzaxZOEKNgIH3MtdanmMzMmoETxCjIDuYZ350Z1SkSzcwazQliFGQH826g\nNrOW4wQxCgYGKw/UZ2bWzJwgRkFyB+EGajNrLTVd9krqAI4FDgZ2AA9GxPp6BtZMsoMF30GYWcsZ\n8awm6TDgo8Crgd8BG4BxwBGStgNfAq6NiGK9Ax3LBgbzHDx1XKPDMDMbVdUue/8B+CLwl+UzvgFI\nOoBkCtG3A9fWJ7zmkM25kdrMWs+IZ7WIOGeEz9YDV4x6RE3ITzGZWSsasZFa0rmS3l6h/O2S3lq/\nsJqLn2Iys1ZU7SmmC4DvVSi/Afib0Q+n+eQLRXYOFd2L2sxaTrUE0RURA8MLIyILeN5LIJtLh9nw\nY65m1mKqJYheSROGF0qaBHTXJ6TmkvVIrmbWoqoliK8C10s6tFQgaR5wXfpZ29s9kqsThJm1lhET\nRET8C/AD4HZJ/ZI2AbcBP4qIy6vtXNIZkh6WtErSxRU+/4Kk+9LXSklbhn0+WdJaSVfu22HtP9t8\nB2FmLarqWS0i/h3497RaiYjYVsuOJWWAq4DTgLXAEkmLImJF2b4/XLb+BcALh+3m74Hba/m+RvEd\nhJm1qmo9qT8yrCgkbQR+GRGPVNn3CcCqiFid7us64CxgxV7WPwf4ZNl3vwg4EPgJ0FfluxrGkwWZ\nWauq1gYxadhrMsnJ+seSFlbZdjbweNny2rTsadI2jvnAz9PlDuBzwIUjfYGk8yUtlbR0w4YNVcKp\nj9JkQa5iMrNWU60n9aWVyiVNB35K0lg9GhYC10dEIV1+L7A4ItZKe5+EJyKuBq4G6Ovri72uWEeu\nYjKzVvWMzmoRsUkjnbkT64BDypbnpGWVLATeV7b8UuBlkt4LTAS6JQ1ExNMauhttwI3UZtaintFZ\nTdIrgM1VVlsCLJA0nyQxLCQZ3G/4vo4EpgF3lsoi4m1ln78T6BuLyQGSO4hMh+jp9NQaZtZaqjVS\nPwAMr7qZDjwBvGOkbSMiL+n9wI1ABrgmIpZLugxYGhGL0lUXAtcNHy22WWQH80zozlD9hsrMrLlU\nu4N4/bDlAPrToTaqiojFwOJhZZcMW/5UlX18DfhaLd/XCAODBSaN86gjZtZ6qjVSPzq8TNIESecC\n50TE6+oWWZPwdKNm1qpqqjiX1C3pTyV9F3gSeBXw73WNrEl4siAza1XV2iBOJ+nAdjpwC/B14MUR\n8ef7Ibam4LkgzKxVVbuD+AnwHOCUiDg3In4ItPX808MljdROEGbWeqqd2Y4necrop5JWk3SMc4V7\nmexgwVVMZtaSqo3mel9EXBwRh5GMk3Qc0CXpx5LO3y8RjnFJFZNzppm1npp7d0XEryLiApIe0V8A\nTqxbVE0iItKnmHwHYWatZ8QEkU4OtIeIKEbETRHxLiXm1Cu4sW4wXyRfDCcIM2tJ1c5sl6cjq/4A\nWAZsAMYBhwOnAq8mqXpaW8cYxyxPN2pmraxaR7k3SzoKeBvwLuAgYDvwEEkP6X+MiJ11j3KMGvBI\nrmbWwmqZUW4F8PH9EEvT2T2Sqxupzaz1eAjSZyGbThbkOwgza0VOEM+CJwsys1bmBPEseLIgM2tl\ntQ7WJ0nnSrokXZ4r6YT6hjb2+Q7CzFpZrXcQ/5dkGtBz0uVtwFV1iaiJ+A7CzFpZrWe2l0TE8ZLu\nBYiIzZK66xhXU9jVSN3tp5jMrPXUegcxJClDOv2opFl4VFeyuTzjujrozLgpx8xaT61ntn8Dvgcc\nIOnTwC+Bf6xbVE3Cc0GYWSur6ewWEd+UtIxkJjkBb4iIh+oaWRPwQH1m1sqqnt3SqqXlEXEk8Nv6\nh9Q8PFmQmbWyqlVMEVEAHpY0dz/E01RcxWRmrazWNohpwHJJP5O0qPSqtpGkMyQ9LGmVpIsrfP4F\nSfelr5WStqTlx0m6U9JySb+R9JZ9O6z9I5lNzk8wmVlrqvXy9+/2dcdp1dRVwGkkw4EvkbQoHfwP\ngIj4cNn6FwAvTBe3A+dFxO8kHQwsk3RjRGzZ1zjqKTuY59AZ4xsdhplZXdR0BxERt5G0P0xKXw+l\nZSM5AVgVEasjIkcyn/VZI6x/DvDt9PtWRsTv0vdPAOuBWbXEuj+5isnMWlmtQ22cDdwNvBk4G/i1\npDdV2Ww28HjZ8tq0rNL+DwXmAz+v8NkJQDfw+1pi3Z/8FJOZtbJaz24fB14cEethV0e5nwLXj1Ic\nC4Hr0wbxXSQdBPwn8I6IeFrHPEnnA+cDzJ27f9vQi8Ugmys4QZhZy6q1kbqjlBxS/TVsuw44pGx5\nTlpWyULS6qUSSZOB/wY+HhF3VdooIq6OiL6I6Js1a//WQGVznizIzFpbrZe/P5F0I7tP4m8Bflxl\nmyXAAknzSRLDQuCtw1eSdCTJU1J3lpV1k/Tc/npEjNZdyqjyZEFm1upq7Ul9kaQ3AqekRVdHxPeq\nbJOX9H7gRiADXBMRyyVdBiyNiNJjsguB6yIiyjY/G/hfwAxJ70zL3hkR99V0VPuBR3I1s1ZX09kt\nvQtYHBE3pMu9kuZFxJqRtouIxcDiYWWXDFv+VIXtvgF8o5bYGmXXXBDuSW1mLarWNojvsuforYW0\nrG15siAza3W1JojOtC8DAOn7tp4PolTFNGmcE4SZtaZaE8QGSWeWFiSdBWysT0jNofQUk+8gzKxV\n1Xp2+yvgm5KuJBnu+3HgvLpF1QQGdj3F5Mdczaw11foU0++BEyVNTJcH6hpVE8j6KSYza3G1DrXx\nwbTjWha4QtI9kk6vb2hjW3YwT4egt8t3EGbWmmptg3hXRDwFnA7MAN4OfKZuUTWBgXSyIEmNDsXM\nrC5qTRCls+BrSXo3Ly8ra0seqM/MWl2tCWKZpJtIEsSNkiaxZ7+ItuPJgsys1dV6Cfxu4DhgdURs\nlzQD+PP6hTX2eS4IM2t1tT7FVATuKVvuJxnRtW25isnMWl2tVUw2zIAThJm1OCeIZyibcxWTmbW2\nms9wkjLAgeXbRMRj9QiqGQzszLuR2sxaWq3DfV8AfBL4A7ufXgrgmDrFNeYlTzH5DsLMWletZ7gP\nAs9NG6fbXi5fJFcoMtFzQZhZC6u1DeJxYGs9A2kmngvCzNpBrWe41cCtkv4bGCwVRsTn6xLVGLdr\nulHPBWFmLazWM9xj6aubNp8oCHbPBeGnmMysldXaUe5SAA/3nXAVk5m1g1qH+36+pHuB5cByScsk\nHV3f0Mau0mRBE/2Yq5m1sFobqa8GPhIRh0bEocDfAF+uX1hjm+8gzKwd1JogJkTELaWFiLgVmFCX\niJpAqZF6gh9zNbMWVmuCWC3p7yTNS1+fIHmyaUSSzpD0sKRVki6u8PkXJN2XvlZK2lL22Tsk/S59\nvaP2Q6o/TzdqZu2g1jPcu4BLgRvS5V+kZXuVDs1xFXAasBZYImlRRKworRMRHy5b/wLghen76SQ9\nt/tIemwvS7fdXGO8deUqJjNrB7U+xbQZ+MA+7vsEYFVErAaQdB1wFrBiL+ufQ5IUAF4D3BwRm9Jt\nbwbOAL69jzHUxcBgge5MB92dHuvQzFrXiAlC0hUR8SFJPyS5kt9DRJw5wuazSXpgl6wFXrKX7zkU\nmA/8fIRtZ1fY7nzgfIC5c+eOEMroSuaC8BNMZtbaqt1B/Gf681/qHMdC4PqIKOzLRhFxNckTVvT1\n9T0tgdWLJwsys3YwYh1JRCxL3x4XEbeVv0imIB3JOuCQsuU5aVklC9mz+mhftt3vPN2ombWDWivR\nKz1F9M4q2ywBFkiaL6mbJAksGr6SpCOBacCdZcU3AqdLmiZpGnB6WjYmZHO+gzCz1letDeIc4K3A\nfEnlJ/dJwKaRto2IvKT3k5zYM8A1EbFc0mXA0ogo7W8hcF1ERNm2myT9PUmSAbis1GA9FgwMFpjS\n29XoMMzM6qraZfCvgCeBmcDnysq3Ab+ptvOIWAwsHlZ2ybDlT+1l22uAa6p9RyMM7Bxi9tRxjQ7D\nzKyuRkwQEfEo8Cjw0v0TTnPIDhbci9rMWl6tg/WdKGmJpAFJOUkFSU/VO7ixyk8xmVk7qLWR+kqS\njmy/A3qBvyDpJd12IoJsLs8kTxZkZi2u5q7AEbEKyEREISL+g6Rnc9vZMVSgGB5mw8xaX61nue3p\no6r3SfosScN1W44zMeBxmMysTdR6kn87yaOq7weyJJ3Y/qxeQY1lWU8WZGZtotbB+h5N3+4gGdW1\nbWU9F4SZtYlqHeUeoMIgfSURccyoRzTGDXguCDNrE9XOcq9Pf74v/VkavO9cRkgcrcxzQZhZu6il\noxySTouIF5Z99FFJ9wBPmyWu1bmR2szaRa2N1JJ0ctnCSfuwbUvZ3UjtBGFmra3Ws9y7gWskTQEE\nbKbKlKOtancVk59iMrPWVutTTMuAY9MEQURsrWtUY9iAn2IyszZR7SmmcyPiG5I+MqwcgIj4fB1j\nG5Oyg3nGd2fo6FCjQzEzq6tql8ET0p+T6h3IWJcvFLn2zke5bsnjzJnW2+hwzMzqrtpTTF9Kf7Z1\n57ilazbxie8/yG//ZxunPncWl555dKNDMjOru2pVTP820ucR8YHRDWds2TgwyGd+/FuuX7aWg6eM\n49/PfRGvOfrAXVVsZmatrFoV07L9EsUYtGZjljOv/CXbcwX+6uWH8YFXHc54N0ybWRupVsV07f4K\nZKy5a3U/T+3Mc8N7T+L4udMaHY6Z2X5X0yWxpFnAR4GjgF2TMUfEK+sUV8P1Z3MAHHXQ5AZHYmbW\nGLX2hv4m8BAwn2Q01zXAkjrFNCb0D+SY2NPJuC53iDOz9lRrgpgREV8FhiLitoh4F9Cydw8Am7KD\nTJ/Q3egwzMwaptZW16H055OSXgc8AUyvT0hjQ3825wRhZm2t1juIf0iH2fgb4ELgK8CHq20k6QxJ\nD0taJaniyK+Szpa0QtJySd8qK/9sWvaQpH/Tfn62tH8gx8yJThBm1r5qvYP4dTr+0lbgFbVsICkD\nXAWcBqwFlkhaFBErytZZAHwMODkiNks6IC0/CTgZKE1I9Evg5cCtNcb7rG3K5nj+bDdQm1n7qvUO\n4g5JN0l6t6Ran/k8AVgVEasjIgdcB5w1bJ33AFdFxGaAiFiflgfJ01LdQA/QBfyhxu991iKC/uwg\n0yf07K+vNDMbc2pKEBFxBPAJ4GhgmaQfSTq3ymazgcfLltemZeWOAI6QdIekuySdkX7fncAtwJPp\n68aIeGj4F0g6X9JSSUs3bNhQy6HUZNtgnqFCuIrJzNpazZP+RMTdEfERkjuDTcBodKLrBBYApwLn\nAF+WNFXS4cDzgDkkSeWVkl5WIaarI6IvIvpmzZo1CuEkNg0kfSDcSG1m7aymBCFpsqR3SPox8CuS\nq/oTqmy2DjikbHlOWlZuLbAoIoYi4hFgJUnC+FPgrogYiIgB4MfAS2uJdTT0ZwcBJwgza2+13kHc\nDxwHXBYRR0TER9NJhEayBFggab6kbmAhsGjYOt8nuXtA0kySKqfVwGPAyyV1SuoiaaB+WhVTvfSn\ndxAz3AZhZm2s1qeYnhMRsS87joi8pPcDNwIZ4JqIWC7pMmBpRCxKPztd0gqgAFwUEf2SrifpiPcA\nSYP1TyLih/vy/c/GpnSYjRlugzCzNlbrlKP7lBzKtlsMLB5Wdsmw/X4kfZWvUwD+8pl852gojcPk\nKiYza2c1N1K3k/6BHBO6Mx6HyczamhNEBZuyg8yY6PYHM2tvtT7F9Nn0SaYuST+TtKGGfhBNy+Mw\nmZnVfgdxekQ8BbyeZKjvw4GL6hVUo/UP5JjhBGFmba7WBFFqzH4d8N10XKaWtSmb8xNMZtb2an3M\n9UeSfgvsAP46nWFuZ/3CapyIYFM253GYzKzt1ToW08XASUBfRAwBWZ4+8F5L2DaYJ1couorJzNpe\nrY3UbyaZTa4g6RPAN4CD6xpZg5TGYXIVk5m1u1rbIP4uIrZJOgV4NfBV4Iv1C6tx3EnOzCxRa4Io\npD9fB1wdEf9NMldDy+kfSAbq8zhMZtbuak0Q6yR9CXgLsFhSzz5s21RK4zBNdxWTmbW5Wk/yZ5MM\nrPeaiNgCTKdF+0GUqpjcSG1m7a7Wp5i2A78HXpOO0HpARNxU18gaZFPW4zCZmUHtTzF9EPgmcED6\n+oakC+oZWKP0Dwy6esnMjNo7yr0beElEZAEk/TNwJ/B/6hVYo/Rnc26gNjOj9jYIsftJJtL3Gv1w\nGm9T1uMwmZlB7XcQ/wH8WtL30uU3kPSFaDn9AzmOOmhyo8MwM2u4WmeU+7ykW4FT0qI/j4h76xZV\ng5TGYfJcEGZmNSQISRlgeUQcCdxT/5AaZ8DjMJmZ7VK1DSKdH/phSXP3QzwN1T/gYTbMzEpqbYOY\nBiyXdDfJSK4ARMSZdYmqQXZ1kvNjrmZmNSeIv6trFGPEpl29qN0GYWY2YhWTpMMlnRwRt5W/SB5z\nXVtt55LOkPSwpFWSLt7LOmdLWiFpuaRvlZXPlXSTpIfSz+ft26Htu9JAfe4oZ2ZWvQ3iCuCpCuVb\n08/2Km3cvgr4Y+Ao4BxJRw1bZwHwMeDkiDga+FDZx18HLo+I5wEnAOurxPqseRwmM7PdqiWIAyPi\ngeGFadm8KtueAKyKiNURkQOu4+mz0L0HuCoiNqf7XQ+QJpLOiLg5LR9Ix4OqK4/DZGa2W7UEMXWE\nz3qrbDsbeLxseW1aVu4I4AhJd0i6S9IZZeVbJN0g6V5Jl6d3JHW1KZtz9ZKZWapaglgq6T3DCyX9\nBbBsFL6/E1gAnAqcA3xZ0tS0/GXAhcCLgecA76wQx/mSlkpaumHDhmcdzMaBQaa7gdrMDKj+FNOH\ngO9Jehu7E0IfyWxyf1pl23XAIWXLc9KycmuBX0fEEPCIpJUkCWMtcF9ErAaQ9H3gRIYN7xERVwNX\nA/T19UWVeKralM3xR5PHPdvdmJm1hBHvICLiDxFxEnApsCZ9XRoRL42I/6my7yXAAknzJXUDC4FF\nw9b5PsndA5JmklQtrU63nSppVrreK4EVNR7TM7Ypm3MnOTOzVK1jMd0C3LIvO46IfDq50I1ABrgm\nIpZLugxYGhGL0s9Ol7SC5NHZiyKiH0DShcDPJInk7uXL+/L9+yoi6B9wG4SZWUmtHeWekYhYDCwe\nVnZJ2fsAPpK+hm97M3BMPT7yNqgAAAtvSURBVOMrVxqHaabbIMzMgNrng2h5pV7UrmIyM0s4QaQ2\nlgbqcxWTmRngBLFL6Q7CVUxmZgkniNSmrMdhMjMr5wSRKlUxeRwmM7OEE0RqUzbHeI/DZGa2ixNE\nKpmL2ncPZmYlThCp/mzO4zCZmZVxgkj1Dwy6/cHMrIwTRGpTNucEYWZWxgmCdBwmzwVhZrYHJwjS\ncZjyRd9BmJmVcYJgdy/qGW6kNjPbxQmC5AkmcC9qM7NyThBAv3tRm5k9jRMEu8dhmjHRVUxmZiVO\nEOyuYvIdhJnZbk4QJFVMHofJzGxPThAkTzF5Jjkzsz05QZBUMbn9wcxsT04QJI3Ubn8wM9uTEwRJ\nG4SrmMzM9tT2CaI0DpPngjAz21NdE4SkMyQ9LGmVpIv3ss7ZklZIWi7pW8M+myxpraQr6xVjNlfw\nOExmZhV01mvHkjLAVcBpwFpgiaRFEbGibJ0FwMeAkyNis6QDhu3m74Hb6xUjwFC+yOuPOYgj/2hy\nPb/GzKzp1C1BACcAqyJiNYCk64CzgBVl67wHuCoiNgNExPrSB5JeBBwI/AToq1eQ0yZ0c+Vbj6/X\n7s3MmlY9q5hmA4+XLa9Ny8odARwh6Q5Jd0k6A0BSB/A54MKRvkDS+ZKWSlq6YcOGUQzdzMwa3Ujd\nCSwATgXOAb4saSrwXmBxRKwdaeOIuDoi+iKib9asWXUP1sysndSzimkdcEjZ8py0rNxa4NcRMQQ8\nImklScJ4KfAySe8FJgLdkgYiomJDt5mZjb563kEsARZImi+pG1gILBq2zvdJ7h6QNJOkyml1RLwt\nIuZGxDySaqavOzmYme1fdUsQEZEH3g/cCDwEfCcilku6TNKZ6Wo3Av2SVgC3ABdFRH+9YjIzs9op\nIhodw6jo6+uLpUuXNjoMM7OmImlZRFR8UrTRjdRmZjZGOUGYmVlFLVPFJGkD8GgNq84ENtY5nEZr\nh2OE9jjOdjhGaI/jHKvHeGhEVOwn0DIJolaSlu6tvq1VtMMxQnscZzscI7THcTbjMbqKyczMKnKC\nMDOzitoxQVzd6AD2g3Y4RmiP42yHY4T2OM6mO8a2a4MwM7PatOMdhJmZ1cAJwszMKmqbBFHL9KfN\nSNI1ktZLerCsbLqkmyX9Lv05rZExPluSDpF0S9nUtB9My1vtOMdJulvS/elxXpqWz5f06/Rv9/+l\ng182NUkZSfdK+lG63IrHuEbSA5Luk7Q0LWuqv9m2SBBl05/+MXAUcI6koxob1aj5GnDGsLKLgZ9F\nxALgZ+lyM8sDfxMRRwEnAu9L//1a7TgHgVdGxLHAccAZkk4E/hn4QkQcDmwG3t3AGEfLB0kG8Sxp\nxWMEeEVEHFfW/6Gp/mbbIkFQNv1pROSA0vSnTS8ibgc2DSs+C7g2fX8t8Ib9GtQoi4gnI+Ke9P02\nkhPLbFrvOCMiBtLFrvQVwCuB69Pypj9OSXOA1wFfSZdFix3jCJrqb7ZdEkQt05+2kgMj4sn0/f+Q\nzO3dEiTNA14I/JoWPM606uU+YD1wM/B7YEs6fD60xt/uFcDfAsV0eQatd4yQJPebJC2TdH5a1lR/\ns/WcUc7GgIgISS3xLLOkicB/AR+KiKeSC89EqxxnRBSA49Kpd78HHNngkEaVpNcD6yNimaRTGx1P\nnZ0SEeskHQDcLOm35R82w99su9xB1DL9aSv5g6SDANKf6xscz7MmqYskOXwzIm5Ii1vuOEsiYgvJ\nJFovBaZKKl3MNfvf7snAmZLWkFT1vhL4V1rrGAGIiHXpz/Ukyf4Emuxvtl0SRC3Tn7aSRcA70vfv\nAH7QwFietbSO+qvAQxHx+bKPWu04Z6V3DkjqBU4jaW+5BXhTulpTH2dEfCwi5qTTCS8Efh4Rb6OF\njhFA0gRJk0rvgdOBB2myv9m26Ukt6bUkdZ8Z4JqI+HSDQxoVkr5NMq/3TOAPwCdJ5vr+DjCXZAj0\nsyNieEN205B0CvAL4AF211v/b5J2iFY6zmNIGi4zJBdv34mIyyQ9h+RqezpwL3BuRAw2LtLRkVYx\nXRgRr2+1Y0yP53vpYifwrYj4tKQZNNHfbNskCDMz2zftUsVkZmb7yAnCzMwqcoIwM7OKnCDMzKwi\nJwgzM6vICcJGjaSQ9Lmy5QslfWqU9v01SW+qvuaz/p43S3pI0i0VPrs8HWX18mew3+PSR63HLEkD\n1dequN0bnsngl8/0+2z/cYKw0TQIvFHSzEYHUq6sh24t3g28JyJeUeGz84FjIuKiZxDGccA+JQgl\nmuH/6BtIRkm2FtMMf3zWPPIk8+5+ePgHw+8ASlePkk6VdJukH0haLekzkt6WzovwgKTDynbzaklL\nJa1Mx/QpDW53uaQlkn4j6S/L9vsLSYuAFRXiOSfd/4OS/jktuwQ4Bfjq8LuEdD8TgWWS3pL2ev6v\n9HuXSDo5Xe8ESXcqmevgV5Kem/bevwx4Szo3wFskfUrShWX7f1DSvPT1sKSvk/S8PUTS6ek+75H0\n3XRMKtLf1Yr0uP+lwjG+PP2++9J4Sj17Lyr7fV1a6R9yb+tIOi8tu1/Sf0o6CTgTuDz9nsPS10+U\nDFL3C0lHptvOT4/jAUn/UOl7bYyJCL/8GpUXMABMBtYAU4ALgU+ln30NeFP5uunPU4EtwEFAD8kY\nPJemn30QuKJs+5+QXNQsIBnxcxzJVf0n0nV6gKXA/HS/WWB+hTgPBh4DZpH0cv058Ib0s1uBvr0d\nX9n7b5EMxgZJr9iH0veTgc70/auB/0rfvxO4smz7T5H0Ii4tPwjMS19F4MS0fCZwOzAhXf4ocAnJ\nCKgPs7uz69QK8f4QODl9PzE91tNJkrjS3+WPgP817N+k4jrA0cBKYGa63vS9/Nv+DFiQvn8JyXAa\nkAwzcV76/n3lv0+/xubLo7naqIpklNWvAx8AdtS42ZJIh0CW9HvgprT8AaC8quc7EVEEfidpNclI\np6cDx5TdnUwhSSA54O6IeKTC970YuDUiNqTf+U2SE+D3a4wXkpP/Udo9ouzk9Mp+CnCtpAUkwz13\n7cM+Sx6NiLvS9yeSVN/ckX5XN3AnsBXYSXK38yOSk/hwdwCfT4/vhohYK+l0kt/Zvek6E0l+X7eX\nbbe3dY4FvhsRGwGiwhAR6e/gJOC7Zb+bnvTnycCfpe//k2SSIBvDnCCsHq4A7gH+o6wsT1qlmdar\nl08pWT7mTrFsucief6PDx4UJkqvcCyLixvIPlIzzk31m4dekg+Qqf+ew770SuCUi/lTJ3BW37mX7\nXb+P1Liy9+VxC7g5Is4ZvgNJJwCvIhnk7v0kI6PuEhGfkfTfJG0fd0h6Tbq/f4qIL41wbBXXkXTB\nCNuUdJDM7XDcXj732D5NxG0QNurSK8vvsOe0kWuAF6Xvz+SZXVm/WVJH2i7xHJIqlhuBv1YyHDiS\njlAyeuZI7gZeLmmmkulozwFu28dYbgJ2nTAllU6IU9g9VPU7y9bfBkwqW14DHJ9uezxJtVgldwEn\nSzo8XXdCeowTgSkRsZikzefY4RtKOiwiHoiIfyYZ0fhIkt/Xu8raMWYrma+g3N7W+TnJv8GMtHz6\n8GOLiKeARyS9OV1Hkkqx3UEygivA2/ZyvDaGOEFYvXyOpP685MskJ+X7SeY4eCZX94+RnNx/DPxV\nevX+FZJG6HskPQh8iSp3xml11sUkQ0zfDyyLiH0ddvkDQF/aYLsC+Ku0/LPAP0m6d1gct5BUSd0n\n6S0kc1tMl7Sc5Op/5V5i3UCSaL4t6Tck1UtHkpyQf5SW/RL4SIXNP5Q2fv8GGAJ+HBE3kbSf3Cnp\nAZJpPssTF3tbJyKWA58Gbkv/HUtDr18HXJQ2hB9GcvJ/d7rOcnZP7/tBkvnEH6A1ZoxreR7N1czM\nKvIdhJmZVeQEYWZmFTlBmJlZRU4QZmZWkROEmZlV5ARhZmYVOUGYmVlF/x+9BCyHDnPjUQAAAABJ\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i07QnorqnQHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=pd.DataFrame(var_selected)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTMqzx_vnQHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result['rfecv_scores']=rfecv.grid_scores_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t3NA_JAnQHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.to_csv('selected_variable_astrun.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vayk_v1ZnQHn",
        "colab_type": "code",
        "outputId": "f7cc4597-a02d-4599-e985-7d3516edb856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "zmydatatrain.iloc[:, zmydatatrain.columns != 'fraud_label'].columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ssn_count0_date', 'ssn_count1_date', 'ssn_count3_date',\n",
              "       'ssn_count7_date', 'ssn_count14_date', 'ssn_count30_date',\n",
              "       'ssn_count180_date', 'address_count0_date', 'address_count1_date',\n",
              "       'address_count3_date',\n",
              "       ...\n",
              "       'ssnfulladdress_days_since_last_seen',\n",
              "       'namehomephone_days_since_last_seen',\n",
              "       'namefulladdress_days_since_last_seen',\n",
              "       'fulladdressdob_days_since_last_seen',\n",
              "       'fulladdresshomephone_days_since_last_seen',\n",
              "       'fulladdressnamedob_days_since_last_seen',\n",
              "       'dobhomephone_days_since_last_seen',\n",
              "       'homephonenamedob_days_since_last_seen', 'dayofweek_risk', 'random'],\n",
              "      dtype='object', length=306)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yem-3jRRnQHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrapper_selected=var_selected[:30]['variable'].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiACzzzov3Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrapper_selected.append('fraud_label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yClQU5qnQHs",
        "colab_type": "code",
        "outputId": "d8554148-a948-4354-e80c-7289ca277231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "wrapper_selected"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fulladdress_count1_date',\n",
              " 'fulladdress_count30_date',\n",
              " 'fulladdress_days_since_last_seen',\n",
              " 'fulladdress_nunique1_dob',\n",
              " 'fulladdresshomephone_count30_date',\n",
              " 'fulladdresshomephone_days_since_last_seen',\n",
              " 'namedob_count14_date',\n",
              " 'namedob_count30_date',\n",
              " 'namedob_days_since_last_seen',\n",
              " 'ssn_days_since_last_seen',\n",
              " 'ssndob_count30_date',\n",
              " 'ssndob_days_since_last_seen',\n",
              " 'ssnfname_days_since_last_seen',\n",
              " 'ssnfullname_count30_date',\n",
              " 'ssnfullname_days_since_last_seen',\n",
              " 'ssnlname_count30_date',\n",
              " 'ssnlname_days_since_last_seen',\n",
              " 'ssnnamedob_count30_date',\n",
              " 'ssnnamedob_days_since_last_seen',\n",
              " 'ssnlname_count180_date',\n",
              " 'fulladdresshomephone_count14_date',\n",
              " 'fulladdress_nunique3_ssn',\n",
              " 'address_days_since_last_seen',\n",
              " 'ssnfname_count14_date',\n",
              " 'ssnlname_count14_date',\n",
              " 'ssnfname_count30_date',\n",
              " 'ssnfullname_count180_date',\n",
              " 'ssnfname_count180_date',\n",
              " 'namedob_count180_date',\n",
              " 'ssnnamedob_count180_date',\n",
              " 'fraud_label']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqz0LCuLnQHz",
        "colab_type": "text"
      },
      "source": [
        "### Split zmydatatrain into train and test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu5aPFsqwSh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwcFlcFMQtYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_copy=pd.read_csv('/content/drive/Shared drives/DSO562 Fraud Project/Project2/Data_Modeling/X_train.csv')\n",
        "X_test_copy=pd.read_csv('/content/drive/Shared drives/DSO562 Fraud Project/Project2/Data_Modeling/X_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oArZsOdKRJGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=X_test.drop(columns=['Unnamed: 0'])\n",
        "X_train=X_train.drop(columns=['Unnamed: 0'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKVwOmFiR-s0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test=pd.read_csv('/content/drive/Shared drives/DSO562 Fraud Project/Project2/Data_Modeling/y_test.csv')\n",
        "y_train=pd.read_csv('/content/drive/Shared drives/DSO562 Fraud Project/Project2/Data_Modeling/y_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOW-pcJGQ5-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test=y_test['fraud_label']\n",
        "y_train=y_train['fraud_label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZqApRX041g_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varall=pd.read_csv('/content/drive/My Drive/Spring 2020/DSO 562 - Fraud Analytics/Project 2/selected_variables.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYKaANWLjvjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varall2=pd.read_csv('/content/drive/Shared drives/DSO562 Fraud Project/Project2/selected_variables_version2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9uqUPamkHFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varall=varall2['variable'][:30]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uMUFhqtiUsw",
        "colab_type": "code",
        "outputId": "0222183f-4f86-442b-8cd7-94e28262368a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(varall)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lVxvXiO5nUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables=varall.to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fTAp017aYJm",
        "colab_type": "code",
        "outputId": "2e97aa09-b81c-49ea-efd4-b6bd058fed9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "variables"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fulladdress_count30_date',\n",
              " 'fulladdress_days_since_last_seen',\n",
              " 'fulladdress_nunique1_dob',\n",
              " 'fulladdress_nunique1_ssnfname',\n",
              " 'fulladdress_nunique3_ssn',\n",
              " 'fulladdress_nunique3_ssnfname',\n",
              " 'fulladdresshomephone_count14_date',\n",
              " 'fulladdresshomephone_count30_date',\n",
              " 'fulladdresshomephone_days_since_last_seen',\n",
              " 'namedob_count30_date',\n",
              " 'namedob_days_since_last_seen',\n",
              " 'ssn_days_since_last_seen',\n",
              " 'ssndob_count14_date',\n",
              " 'ssndob_count30_date',\n",
              " 'ssndob_days_since_last_seen',\n",
              " 'ssnfname_days_since_last_seen',\n",
              " 'ssnfullname_days_since_last_seen',\n",
              " 'ssnlname_days_since_last_seen',\n",
              " 'ssnnamedob_count14_date',\n",
              " 'ssnnamedob_count30_date',\n",
              " 'ssnnamedob_days_since_last_seen',\n",
              " 'namedob_count14_date',\n",
              " 'ssnfname_count180_date',\n",
              " 'ssnlname_count30_date',\n",
              " 'ssnfullname_count30_date',\n",
              " 'ssnfname_count30_date',\n",
              " 'address_days_since_last_seen',\n",
              " 'address_count3_date',\n",
              " 'namedob_count180_date',\n",
              " 'ssnnamedob_count180_date']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1404
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM7hY-x7JXw9",
        "colab_type": "code",
        "outputId": "74a35117-e005-45cd-8377-4dbdf4571bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(variables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1405
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW25UyQ8Wtx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=X_test_copy[variables]\n",
        "X_train=X_train_copy[variables]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMMeic-TnQH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "#datasplit=zmydatatrain[variables]\n",
        "#datasplit1 = datasplit.drop(\"fraud_label\", axis = 1)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(datasplit1, datasplit['fraud_label'], test_size = 0.20, random_state = 9, stratify = datasplit['fraud_label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpZLK-YXwZP2",
        "colab_type": "code",
        "outputId": "4b003a29-d1f1-4432-9933-ac6ea61aac75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "!pip install imblearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (0.22.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2awbFBNbwYe3",
        "colab_type": "code",
        "outputId": "d4dfcf26-c083-46e8-85b8-62c908caadd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
        "  \n",
        "# import SMOTE module from imblearn library \n",
        "# pip install imblearn (if you don't have imblearn in your system) \n",
        "from imblearn.over_sampling import SMOTE \n",
        "sm = SMOTE(random_state = 2) \n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
        "  \n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
        "  \n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, counts of label '1': 9189\n",
            "Before OverSampling, counts of label '0': 626807 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After OverSampling, the shape of train_X: (1253614, 15)\n",
            "After OverSampling, the shape of train_y: (1253614,) \n",
            "\n",
            "After OverSampling, counts of label '1': 626807\n",
            "After OverSampling, counts of label '0': 626807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "L2Oem94JnQH1",
        "colab_type": "code",
        "outputId": "9ffce2f4-9fe5-4c5e-898a-1c08904873c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "model=LogisticRegression()\n",
        "model.fit(X_train_res, y_train_res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoL65NlanQH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fdrsample=len(model.predict_proba(X_test))*0.03"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18qStcYOnQH5",
        "colab_type": "code",
        "outputId": "7987ba91-7df2-4800-d95a-09ef8967aa2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "fdrsample"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4770.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1342
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QbxBGv4H-yJ",
        "colab_type": "text"
      },
      "source": [
        "Training Effectiveness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqLhsrcOH-HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict=model.predict_proba(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Fo_0f2nQH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yactual=y_train.reset_index()\n",
        "yactual=yactual['fraud_label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBliwCU9nQIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame(predict,yactual)\n",
        "df=df.reset_index()\n",
        "df=df.rename(columns={1: 'Pred_Proba'})\n",
        "predict=df.sort_values('fraud_label',ascending=False)\n",
        "predict=predict.sort_values('Pred_Proba',ascending=False)\n",
        "predict.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUdr71tUxfXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict=predict.drop(columns=[0,'index'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NewDlKqk10Kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict=predict[:round(len(X_train)*.03)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG_7yFZVIon2",
        "colab_type": "code",
        "outputId": "f4ac6aaa-584d-487c-fb7f-186b39f1cbff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fraud_label</th>\n",
              "      <th>Pred_Proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19075</th>\n",
              "      <td>0</td>\n",
              "      <td>0.666952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19076</th>\n",
              "      <td>0</td>\n",
              "      <td>0.666952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19077</th>\n",
              "      <td>0</td>\n",
              "      <td>0.666952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19078</th>\n",
              "      <td>0</td>\n",
              "      <td>0.666952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19079</th>\n",
              "      <td>0</td>\n",
              "      <td>0.666952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19080 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       fraud_label  Pred_Proba\n",
              "0                1    1.000000\n",
              "1                1    1.000000\n",
              "2                1    1.000000\n",
              "3                1    1.000000\n",
              "4                1    1.000000\n",
              "...            ...         ...\n",
              "19075            0    0.666952\n",
              "19076            0    0.666952\n",
              "19077            0    0.666952\n",
              "19078            0    0.666952\n",
              "19079            0    0.666952\n",
              "\n",
              "[19080 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPpcc3gY67vi",
        "colab_type": "code",
        "outputId": "02bf38d9-e735-40d0-b089-6c2ac771dd3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sum(predict['fraud_label']==1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3254"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1349
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKO2mYyo21AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainFDR=sum(predict['fraud_label']==1)/(sum(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3trr1YtPI4qY",
        "colab_type": "text"
      },
      "source": [
        "Testing with test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuJUAqujI4We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict=model.predict_proba(X_test)\n",
        "yactual=y_test.reset_index()\n",
        "yactual=yactual['fraud_label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaeDq6m0JBqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame(predict,yactual)\n",
        "df=df.reset_index()\n",
        "df=df.rename(columns={1: 'Pred_Proba'})\n",
        "predict=df.sort_values('fraud_label',ascending=False)\n",
        "predict=predict.sort_values('Pred_Proba',ascending=False)\n",
        "predict.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p351K4foJDc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict=predict[:round(len(X_test)*.03)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyUt4T0TJFCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytestFDR=sum(predict['fraud_label']==1)/(sum(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cF6bleoAmcq",
        "colab_type": "text"
      },
      "source": [
        "Testing Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNY_fu6XDfw4",
        "colab_type": "code",
        "outputId": "27ddfe8d-633e-4f59-87a6-741d3c7d7e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "zmydatatest.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(166493, 307)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1355
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHHskwRODhI7",
        "colab_type": "code",
        "outputId": "3d3cee61-a80d-4a84-b959-a4a16c259e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ztestfraud.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(166493,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSMUL0u2AQ33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatest=zmydatatest[variables]\n",
        "ztestfraud=zmydatatest['fraud_label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vSIJPKxBLZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict=model.predict_proba(datatest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmB-IBLvCnaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame(predict,ztestfraud)\n",
        "df=df.reset_index()\n",
        "df=df.rename(columns={1: 'Pred_Proba'})\n",
        "predict=df.sort_values('fraud_label',ascending=False)\n",
        "predict=predict.sort_values('Pred_Proba',ascending=False)\n",
        "predict.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag0SVmFuGi93",
        "colab_type": "code",
        "outputId": "141f702c-0fe1-43d4-9e64-26775f016c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sum(predict[:4995]['fraud_label']==1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UrFDe_HEcW5",
        "colab_type": "code",
        "outputId": "c64c1eea-60a2-407b-8f8f-4e979e7ee335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sum(predict[:round(len(zmydatatest)*0.03)]['fraud_label']==1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1361
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWO-4UAjEQjG",
        "colab_type": "code",
        "outputId": "d956446c-1430-4222-a056-1032648f2e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ztestfraud.sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1362
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5omeVu1SBrDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ootFDR=sum(predict[:round(len(zmydatatest)*0.03)]['fraud_label']==1)/(sum(ztestfraud))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDgWottnCZdQ",
        "colab_type": "code",
        "outputId": "5ef25bd0-98c9-4104-9f7f-e63f378b15b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "print(f'The train FDR is: {round(trainFDR*100,4)}%\\n\\\n",
        "The test FDR is: {round(ytestFDR*100,4)}%\\n\\\n",
        "The oot FDR is: {round(ootFDR*100,4)}%.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The train FDR is: 35.4119%\n",
            "The test FDR is: 37.0919%\n",
            "The oot FDR is: 32.1039%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhMV4ScNBwqo",
        "colab_type": "code",
        "outputId": "d10e2ecf-0911-4c5d-b6b6-437716305f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>fraud_label</th>\n",
              "      <th>0</th>\n",
              "      <th>Pred_Proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>162192</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81816</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>83877</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83500</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>163870</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166488</th>\n",
              "      <td>9579</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8115</td>\n",
              "      <td>0.1885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166489</th>\n",
              "      <td>120411</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8115</td>\n",
              "      <td>0.1885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166490</th>\n",
              "      <td>94762</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8115</td>\n",
              "      <td>0.1885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166491</th>\n",
              "      <td>33016</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8115</td>\n",
              "      <td>0.1885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166492</th>\n",
              "      <td>137429</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8115</td>\n",
              "      <td>0.1885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>166493 rows  4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         index  fraud_label       0  Pred_Proba\n",
              "0       162192            0  0.0000      1.0000\n",
              "1        81816            1  0.0000      1.0000\n",
              "2        83877            1  0.0000      1.0000\n",
              "3        83500            1  0.0000      1.0000\n",
              "4       163870            1  0.0000      1.0000\n",
              "...        ...          ...     ...         ...\n",
              "166488    9579            0  0.8115      0.1885\n",
              "166489  120411            0  0.8115      0.1885\n",
              "166490   94762            0  0.8115      0.1885\n",
              "166491   33016            0  0.8115      0.1885\n",
              "166492  137429            0  0.8115      0.1885\n",
              "\n",
              "[166493 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f1f36ef2-7cb3-479a-fa0f-3ae63a7b811b",
        "id": "X_OinbI695NH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "cm = confusion_matrix(y_test, model.predict(X_test))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.imshow(cm)\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAHSCAYAAAAe1umcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-HC-J6xnQIj",
        "colab_type": "code",
        "outputId": "f9f08490-52ed-4020-d98a-a5545edf40ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "print(classification_report(y_test, model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98    156703\n",
            "           1       0.25      0.54      0.34      2297\n",
            "\n",
            "    accuracy                           0.97    159000\n",
            "   macro avg       0.62      0.76      0.66    159000\n",
            "weighted avg       0.98      0.97      0.98    159000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85K4D-2SnQIl",
        "colab_type": "code",
        "outputId": "1e020c5a-d855-4e69-c1df-07c9b482b5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = logitrain_X,logitest_X,logitrain_Y,logitest_Y\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1068-b63e7df3429b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogitrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogitest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogitrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogitest_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'logitrain_X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GEzVNBmnQIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(LogisticRegression)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmJM1ZvlnQIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6RPZsJEOqPp",
        "colab_type": "code",
        "outputId": "4c084616-0932-4c4a-8d58-55bc9f56161c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307150    0\n",
              "613834    0\n",
              "559776    0\n",
              "649548    0\n",
              "529900    0\n",
              "         ..\n",
              "528358    0\n",
              "4668      0\n",
              "404148    0\n",
              "440008    0\n",
              "667359    0\n",
              "Name: fraud_label, Length: 159000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 546
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1A8Jb10ryJl",
        "colab_type": "text"
      },
      "source": [
        "##### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHAfpIg5-6X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhU4kOWfAcuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varall2=pd.read_csv('/content/drive/Shared drives/DSO562 Fraud Project/Project2/selected_variables_version2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKNjF40Y5Xgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varall1=pd.read_csv('/content/drive/Shared drives/DSO562 Fraud Project/Project2/Data_w_top_20_features.csv')\n",
        "varlist=varall1.columns.to_list()[1:21]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNqaeVEaq4OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varlist=varall2['variable'][:30].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXey7PvQl0h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varlist=varall2[:30]['variable'].to_list()\n",
        "varlistcopy=varlist.copy()\n",
        "varlist.append('fraud_label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvIiZpu96xM8",
        "colab_type": "code",
        "outputId": "e09a6613-6372-4bd7-dba4-8d7c18ce782a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        }
      },
      "source": [
        "variables=varall2['variable'].to_list()\n",
        "variables"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fulladdress_count1_date',\n",
              " 'fulladdress_count30_date',\n",
              " 'fulladdress_days_since_last_seen',\n",
              " 'fulladdress_nunique1_dob',\n",
              " 'fulladdresshomephone_count30_date',\n",
              " 'fulladdresshomephone_days_since_last_seen',\n",
              " 'namedob_count14_date',\n",
              " 'namedob_count30_date',\n",
              " 'namedob_days_since_last_seen',\n",
              " 'ssn_days_since_last_seen',\n",
              " 'ssndob_count30_date',\n",
              " 'ssndob_days_since_last_seen',\n",
              " 'ssnfname_days_since_last_seen',\n",
              " 'ssnfullname_count30_date',\n",
              " 'ssnfullname_days_since_last_seen',\n",
              " 'ssnlname_count30_date',\n",
              " 'ssnlname_days_since_last_seen',\n",
              " 'ssnnamedob_count30_date',\n",
              " 'ssnnamedob_days_since_last_seen',\n",
              " 'ssnlname_count180_date',\n",
              " 'fulladdresshomephone_count14_date',\n",
              " 'fulladdress_nunique3_ssn',\n",
              " 'address_days_since_last_seen',\n",
              " 'ssnfname_count14_date',\n",
              " 'ssnlname_count14_date',\n",
              " 'ssnfname_count30_date',\n",
              " 'ssnfullname_count180_date',\n",
              " 'ssnfname_count180_date',\n",
              " 'namedob_count180_date',\n",
              " 'ssnnamedob_count180_date',\n",
              " 'fulladdress_count180_date',\n",
              " 'address_count30_date',\n",
              " 'fulladdress_nunique3_dob',\n",
              " 'address_count3_date',\n",
              " 'ssn_count14_date',\n",
              " 'ssn_count30_date',\n",
              " 'fulladdress_count7_date',\n",
              " 'ssnnamedob_count14_date',\n",
              " 'fulladdress_count3_date',\n",
              " 'address_count1_date',\n",
              " 'address_count7_date',\n",
              " 'fulladdress_count14_date',\n",
              " 'address_1_count_address_14_count_Ave',\n",
              " 'address_count180_date',\n",
              " 'fulladdress_nunique3_ssnfname',\n",
              " 'fulladdresshomephone_count180_date',\n",
              " 'ssnfullname_count14_date',\n",
              " 'ssndob_count180_date',\n",
              " 'ssn_count180_date',\n",
              " 'fulladdress_nunique1_ssn',\n",
              " 'fulladdress_1_count_fulladdress_14_count_Ave',\n",
              " 'fulladdress_nunique1_ssnfname',\n",
              " 'address_count14_date',\n",
              " 'ssndob_count14_date']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JN4isRO4yLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n=30\n",
        "variables1=variables[:n]\n",
        "variables1copy=variables[:n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqR9Z1jE7UmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables1.append('fraud_label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGwZaqxz7ysL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables1=varlist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiW_d55su86W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jaXOfMkVtkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "datasplit=zmydatatrain[varlist]\n",
        "datasplit1 = datasplit.drop(\"fraud_label\", axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(datasplit1, datasplit['fraud_label'], test_size = 0.20, random_state = 11, stratify = datasplit['fraud_label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trLFdHmSVyj6",
        "colab_type": "code",
        "outputId": "51bc9114-22f9-4a98-8873-dd4f3320f14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
        "  \n",
        "# import SMOTE module from imblearn library \n",
        "# pip install imblearn (if you don't have imblearn in your system) \n",
        "from imblearn.over_sampling import SMOTE \n",
        "sm = SMOTE(random_state = 2) \n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
        "  \n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
        "  \n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, counts of label '1': 9189\n",
            "Before OverSampling, counts of label '0': 626807 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After OverSampling, the shape of train_X: (1253614, 20)\n",
            "After OverSampling, the shape of train_y: (1253614,) \n",
            "\n",
            "After OverSampling, counts of label '1': 626807\n",
            "After OverSampling, counts of label '0': 626807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWi_ZebX-fq3",
        "colab_type": "code",
        "outputId": "645ce47b-9c8b-4d03-8eaf-4a9c10f375bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "max_depths = np.linspace(4, 7, 3, endpoint=True)\n",
        "train_results = []\n",
        "test_results = []\n",
        "for max_depth in max_depths:\n",
        "   dt = DecisionTreeClassifier(max_depth=max_depth)\n",
        "   dt.fit(X_train_res, y_train_res)\n",
        "   train_pred = dt.predict(X_train)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   # Add auc score to previous train results\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = dt.predict(X_test)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   # Add auc score to previous test results\n",
        "   test_results.append(roc_auc)\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
        "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('AUC score')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.show()\n",
        "# Max Depth best parameter should be 5.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXwUVbbA8d9hDTvIOhIUhkXEDSTi\nuIuKIrigooDiuDM4ioqjyDxnUBmfgwsiCk8FxRUTFBdQWUYUXGZQCIqyCIqMShDZF9nEJOf9cauh\nSDpJN12VdDrn+/n0J91V1TenaO2TqnvPvaKqGGOMMbGqVNYBGGOMKV8scRhjjImLJQ5jjDFxscRh\njDEmLpY4jDHGxKVKWQdQGho1aqQtW7Ys6zCMMaZcWbBgwQZVbVxwe4VIHC1btiQ7O7uswzDGmHJF\nRH6Itt1uVRljjImLJQ5jjDFxscRhjDEmLhWijyOa3377jZycHHbv3l3WoaSMtLQ00tPTqVq1almH\nYowJUYVNHDk5OdSpU4eWLVsiImUdTrmnqmzcuJGcnBxatWpV1uEYY0JUYW9V7d69m4YNG1rSCIiI\n0LBhQ7uCM6YCqLCJA7CkETD79zSmYqiwt6qMKXMrVsDkydCgATRp4h5Nm7qfdeqAJWKTpCxxlJGN\nGzdy5plnAvDzzz9TuXJlGjd2BZrz5s2jWrVqJbZxzTXXMHToUA477LC4fvd5553Hli1b+OSTT/Zu\n69+/P71796ZXr14A5Obm0qhRI7Zs2QLAsmXLGDx4MCtWrKBOnTq0a9eOxx9/nCZNmsT1u43nxx/h\ntNPgp5+i769efV8yKfiIJJfIo3FjiOG/F2OCYomjjDRs2JCFCxcCcO+991K7dm3uuOOO/Y5RVVSV\nSpWi31F87rnn4v69mzZt4quvviItLY0ff/yRQw45pMT37Ny5k549e/LEE0/Qo0cPAN5//302btxo\nieNAbN4M3bvDjh2wYIFLBOvWFX6sXbvv+eLF7vWePdHbrF+/+OTifzRoYFczJiGWOJLMihUruOCC\nC+jUqRNffPEF7733Hvfddx+ff/45u3btok+fPgwbNgyAk08+mTFjxnDkkUfSqFEjBg4cyPTp06lZ\nsyZTpkyJ+qU+efJkevXqRb169cjKymLIkCElxvTyyy9z2mmn7U0awN6rJROn3bvhwgvhu+9g5kw4\n9li3vXnzkt+rCr/8UnRyiTyWLYOPPoKNG917CqpSxV2lFJdc/I8aNYL9NzClJvLxB/13giWOAm67\nDbwLgbh17AiPPZZ4DMuWLePFF18kIyMDgBEjRnDQQQeRm5tL165d6d27Nx06dNjvPVu3buW0005j\nxIgR3H777UyYMIGhQ4cWajszM5MHHniAevXqccUVV8SUOBYvXkznzp0TP7GKLj8frrwSPv4YsrLg\n9NPje78I1K3rHm3alHx8bq5LHtGSi//x7bfumJ07o7dTp07JySWShA46CCpXju+8zAFRha1bYdUq\nyMlxP6M9X7IEgp7jNdTEISLdgdFAZeAZVR1RYP8ooKv3sibQRFXre/sOAZ4BWgAK9FDV70VkIpAB\n/AbMA/6kqr+FeR6lrXXr1nuTBrgv+2effZbc3Fx++uknli5dWihx1KhRg3PPPReAzp078/HHHxdq\n96effuLHH3/khBNOACA/P59ly5bRvn37qCOibJRUgFRh8GDXGT5yJPTpE/7vrFLFfaE3bRrb8Tt2\nFJ9g1q6FlSvh009h/XqXCAuqVAkaNYqtb6ZJE6hVy26bFWHbtpKTwvbt+7+nUiX43e+gRQs4+mjo\n2TOc7q/QEoeIVAbGAt2AHGC+iExV1aWRY1R1sO/4QUAnXxMvAv+rqu+JSG0g8l/pRKC/9/wV4Hrg\nyaDiDuKKIVG1atXa+/zbb79l9OjRzJs3j/r169O/f/+otRL+zvTKlSuTm5tb6JhJkyaxYcMGIlPM\nb926lczMTO677z4aNmzI5s2b9x67adMmGjVqBMARRxzBZ599FtTpVUwjR8Ljj7vkcfvtZR1NdLVq\nQatW7lGS/HzYtKn4fpl16yA72/3cti16OzVqxN4306gRpMisBNu3F58QVq0q/E8mAs2auaTQoQOc\nc457np7ufrZo4ZJGlVK4jxTmr+gCrFDVlQAikgVcCCwt4vh+wD3esR2AKqr6HoCq7s2rqjot8lxE\n5gHpoUSfJLZt20adOnWoW7cua9asYebMmXTv3v2A2srMzGTWrFkcd9xxgEtKPXv25L777uP000/n\nySefpH///lStWpXnn3+erl3dxeCVV17Jgw8+yIwZM/b+7tmzZ9OsWTMOP/zwYE40lWVmwp13wmWX\nwSOPlHU0wYhcWTRq5L7FSrJ7t7tKKapfZt06N8Js4UL3/LcibiIcdFDJCSbyqFevTK5mdu4sOSl4\ngxX307SpSwJt28IZZ0RPCskyeC7MxNEcWOV7nQMcH+1AETkUaAV84G1qB2wRkTe87bOAoaqa53tP\nVeBK4NYi2hwADABiGjmUrI499lg6dOhA+/btOfTQQznppJMOqJ3vvvuONWvW7HcLrG3btqSlpbFg\nwQJ69erF559/TufOnalUqRJt27blqaeeAqBmzZq88847DB48mEGDBlG1alU6duzI6NGjAznHlPbB\nB3DVVW7o7QsvuC/ciigtbd83YElU3TdrcbfN1q2DRYtcEvJdKe+nWrXY+2YaN3ZDoEuwe/e+L/+i\nksOmTYXf17ixSwKtWsGpp+6fENLT3diIGH590hCNNuoiiIZFegPdVfV67/WVwPGqenOUY+8C0lV1\nkO+9z+JuXf0ITAKmqeqzvveMB3ao6m0lxZKRkaEFF3L6+uuv7a/lENi/q89XX8Epp7hvh08+cUNm\nTfD27IENG4rvm/E///XXqM1ovXr81qAJu2o3YWtaEzZWasKa/Cas+rUp3/3ShOWbm/DN1iasowmb\naYB6E280bFg4Efifp6e7vFkeicgCVc0ouD3MK47VuI7tiHRvWzR9gZt8r3OAhb7bXG8Bf8AlE0Tk\nHqAx8KeAYzYmGD/+COee60YkTZ9uSSNM1arBwQe7RxF++w1Wr4acVcqab7ezefk6tq9cx6+r1pG3\nZh1VNq6l5tZ1NNm6DpcavqE5n3AMG6hE4T+u8ytVJr9hYyo1bUKlZlH6Zxo0gZpNoEoTyG+CG/uT\nOsJMHPOBtiLSCpcw+gKXFzxIRNoDDYC5Bd5bX0Qaq+p64Awg2zv+euAc4ExVjTKsw5gytnmzSxrb\nt7srjVhuz5gDlpvrukeK61f4+edITYMAdYA61K3b2l0ZdNh3lVCnBeSlQ5UWUDMdKtXIc0OaC1y5\nVPIee69kVq50PwsOc4qoVSv2vplGjZJ+SHNoiUNVc0XkZmAmbjjuBFVdIiLDgWxVneod2hfIUt89\nM1XNE5E7gPfFjQldAIz3dj8F/ADM9YaLvqGqw8M6D2PiEinwW7ECZsyAo44q64jKtbw896VfXEfz\nmjWFRwbXrr3vVtFRR0W/hVS3biwRVN73hX7kkSUfvmPHvkEART2+/x7mzXPH5eUVbkOk6CHN0Uaf\n1a5d6oMAQh245Y2AmlZg27ACr+8t4r3vAUdH2W5FiyY5+Qv8MjOha9eS31OB5ee7P+KLSwo//VT4\nu7VmzX1f/t26RU8KZTSgyl1Z1KoVW8Vdfr67Oi2pX+bzz93PrVujt5OWVnyC6dnTTTMTIPsSNiYI\nBQv8+vYt64jKVH6++4O6uNFHq1e720x+aWn7kkDXrtGTQspMtVWpkutZb9gQYhlQ8uuv+1/NRBvW\n/PPPblDGunX75jVbvtwShzFJKVLgd9ttyVvgFxBVN4jJnwSiJYWC8zFWq7YvCZxySvSRSA0bpkhS\nCEP16vuGaZVE1VUQrl0bW0FnnCxxlJEgplUHmDBhAj169KBZs2ZR9+/Zs4dmzZrx5z//mfvvv3/v\n9vT0dBYvXkx9b7TPrFmzGDNmDG+99RYA7777LsOGDWP37t1UrVqVc845hwcffPCAzzel+Qv8Ro4s\n62gSourqEIrraM7JcV05flWrulqEFi3gD3/YlxD8SaFxY0sKpUbE3a+rVy+U5i1xlJFYplWPxYQJ\nEzj22GOLTBwzZ86kQ4cOTJo0ab/EUZwvv/yS2267jXfffZd27dqRl5fHuHHj4o6tQogU+J16atIX\n+PknxSuuX2HXrv3fV7nyvqTQuTP06lX4FlKTJkl96iZgljiS0AsvvMDYsWPZs2cPJ554ImPGjCE/\nP59rrrmGhQsXoqoMGDCApk2bsnDhQvr06UONGjWiXqlkZmZy++23M2rUKObNm0eXLl1K/P0PPvgg\nf//732nXrh3g5r668cYbQznXcu2rr+Cii6BdO3jrrTKv8opMildcv8KOHfu/p1IlV/7QogUccwyc\nd17hpNC0adKPDjWlzBIHJDaXelEOcI71xYsX8+abb/Kf//yHKlWqMGDAALKysmjdujUbNmxg0aJF\nAGzZsoX69evzxBNPMGbMGDp27FiorZ07dzJnzhwmTJjAzz//TGZmZkyJY/Hixdx9991xx16hFCzw\nC7jzsaDt2wsngYKvf/ll//eIuPmN0tPhiCPc2lEF+xVKa1I8k1rsP5kkM2vWLObPn793Tqldu3bR\nokULzjnnHJYvX84tt9xCz549Ofvss0tsa+rUqXTr1o20tDQuvfRSOnfuzMiRI6lUqZJNo56IgAv8\ndu4sefrsaJPiNWvmvvwPOwzOOqtwUjj44JSZTNYkGUsckBxzqXtUlWuvvZZ//OMfhfZ99dVXTJ8+\nnbFjx/L666+X2O+QmZnJp59+unca9fXr1/Phhx/StWvXvdOoRzrHC06jvmDBAo444ohgTy4VBFjg\nN2YM3HuvK0wuqHFjlwBat3bzIxbsbG7ePHlmSjUVjyWOJHPWWWfRu3dvbr31Vho1asTGjRvZsWMH\nNWrU2Hvl0LZtW66//noA6tSpwy8F71HgbmV9+umn5OTkUNX7s3P8+PFkZmbStWtXTj/9dF566SWG\nDRtGbm4uEydOpI+3uNCQIUO47LLLOPHEE2nTpg15eXmMHz+egQMHlt4/RDIKsMBv8mQYNMgtAnj2\n2fv3KzRvXubdJcYUyxJHkjnqqKO45557OOuss8jPz6dq1ao89dRTVK5cmeuuuw5VRUT2Do295ppr\nuP766wt1jr/++ut069Ztb9IA6NWrF3fffTdjx47l3nvvZeDAgRxzzDGoKj169KBfv34AdOrUiZEj\nR3LZZZftXTTqwgsvLOV/iSSj6uozAijw++wzl39OOAGmTbMlvU35E9q06snEplUvPSn77zpyJNxx\nhxtIMWrUATfz3/+6Oofatd0KrF7pjjFJqahp1W3ktTElycx0SSPBAr8tW9y0QXv2wLvvWtIw5Zfd\nqjKmOAEV+O3ZA5dc4vrU//UvaN8+4DiNKUUVOnFE+gtMMFLutmdABX6qcOONLgc9/7zrEDemPKuw\nt6rS0tLYuHFj6n3ZlRFVZePGjaSlynCgAAv8RoyACRPg7393Fy/GlHcV9oojPT2dnJwc1q9fX9ah\npIy0tDTSY5m5M9kFWOA3aRL8z//A5ZfDffcFGKMxZajCJo6qVavSKoTphk05t3u3m8UvgAK///zH\nXWGcfDI8+6zNDGtSR4VNHMYUkp8Pf/wjfPRRwgV+333nCsxbtIA337SCPpNaKmwfhzH7iRT4vfYa\nPPJIQgV+mza5Ybf5+a7Az5vJxZiUYVccxgA8+iiMHp3wCn579sDFF7tCv1mzoG3bAGM0JklY4jAm\nK8sV+F16qSvwO8DOCFW44Qb48EOYONEtj2pMKgr1VpWIdBeR5SKyQkSGRtk/SkQWeo9vRGSLb98h\nIvIvEflaRJaKSEtveysR+cxrc5KI2Byh5sDNnu36NU49FV58MaFl7O6/3zUxfLgbRWVMqgotcYhI\nZWAscC7QAegnIh38x6jqYFXtqKodgSeAN3y7XwQeVtXDgS7AOm/7g8AoVW0DbAauC+scTIpbtMiN\noApgBb+JE2HYMJeD/va3AGM0JgmFecXRBVihqitVdQ+QBRQ3xWo/IBPASzBVVPU9AFXdrqo7xZV5\nnwFM9t7zAtArrBMwKWzVqsAK/D7+GK691lWEjx9vw25N6gszcTQHVvle53jbChGRQ4FWwAfepnbA\nFhF5Q0S+EJGHvSuYhsAWVc0tqU1jihQp8PvlF5c0Eijw++Ybd9HSqhW8/rotrmQqhmQZjtsXmKyq\ned7rKsApwB3AccDvgavjaVBEBohItohkW3W42StS4PfNN+72VAIFfhs2uGG3lSq52W4POijAOI1J\nYmEmjtWA/0+5dG9bNH3xblN5coCF3m2uXOAt4FhgI1BfRCKjwYpsU1XHqWqGqmY0tvmrDexf4Pfi\niwkV+EXyz6pVMGWKW+LVmIoizMQxH2jrjYKqhksOUwseJCLtgQbA3ALvrS8ikW/8M4Cl6mYknA30\n9rZfBUwJKX6TSgIs8FN1fRr//rebaf3EEwOM05hyILTE4V0p3AzMBL4GXlXVJSIyXEQu8B3aF8hS\n3zS13i2rO4D3RWQRIMB4b/ddwO0isgLX5/FsWOdgUkikwO/WWxMq8AO45x43I8kDD4C3TLsxFUqF\nXTrWVCBZWdCvnyvwy8pKqFbjhRfg6qvdFcczz9gIKpPabOlYUzEFWOA3e7arDD/zTHjqKUsapuKy\nxGFSV6TAr23bhAv8li1zc1C1aQOTJ0PVqgHGaUw5Y4nDpKZIgV/t2m5djQQK/Navhx49XI3Gu+9C\n/foBxmlMOWSTHJrU4y/w+/jjhAr8du1y62qsWQNz5rhCP2MqOkscJrX4C/xmzoSjjz7gpvLzXUf4\n3Lnu9tTxxwcXpjHlmSUOkzoCXMEP3GSFr74KDz0El1wSUIzGpADr4zCp4y9/CaTAD9wa4f/8JwwY\n4JbqMMbsY4nDpIZHH4XHHgukwG/WLBg4EM4+G8aMsWG3xhRkicOUf1lZ7mrj0ktdAkngm37JEndb\nqn17d5vKht0aU5glDlO+zZ4NV10VSIHf2rVuttuaNd2w23r1AozTmBRineOm/IoU+LVpk3CB386d\ncMEFsG6d61s/5JAA4zQmxVjiMOVTgAV++flw5ZUwfz688QZkFJqZxxjjZ4nDlD9btgRW4AcwdKhL\nGI8+6i5gjDHFs8RhypcAC/wAnn4aHn4Y/vxnuO22gGI0JsVZ4jDlR36+6wj/8EN45ZWEC/xmzoSb\nbnIXL6NH27BbY2Jlo6pM+XHHHW6M7MMPu/U1ErBokRu9e+SRMGkSVLE/oYyJmSUOUz48+iiMGuUK\n/P7yl4SaWrPGDbutUwfeecf9NMbEzv7OMskvUuDXu3fCBX47dsD558OmTa5fPT09wDiNqSAscZjk\nNmeO69c45RR46aWECvzy8uCKK+CLL2DKFOjUKbgwjalILHGY5OUv8JsyJaECP4A773TNPPEEnHde\nQDEaUwFZH4dJTpECv1q1YPr0hAr8AMaO3ddFcvPNAcVoTAVlVxwm+RQs8Etw/o9p0+CWW1zfxsiR\nAcVoTAUW6hWHiHQXkeUiskJEhkbZP0pEFnqPb0Rki29fnm/fVN/2M0Xkc2/7JyLSJsxzMKXs11/3\nFfi9+WbCBX4LF0KfPtCxoyv9qFw5oDiNqcBCu+IQkcrAWKAbkAPMF5Gpqro0coyqDvYdPwjwd1fu\nUtWOUZp+ErhQVb8WkT8DfwOuDuEUTGmLrOAXKfA744yEmsvJccNu69eHt99201oZYxIX5hVHF2CF\nqq5U1T1AFnBhMcf3AzJjaFeBut7zesBPCUVpkkeABX6//OJuTW3b5qZIP/jggGI0xoTax9EcWOV7\nnQMcH+1AETkUaAV84NucJiLZQC4wQlXf8rZfD0wTkV3ANuAPRbQ5ABgAcIjNkZ38IgV+t9yScIFf\nbq5bOXbRIlfgl+DdLmNMAckyqqovMFlV83zbDlXVDOBy4DERae1tHwz0UNV04Dng0WgNquo4Vc1Q\n1YzGjRuHGbtJVIAFfqpussJp09yw2+7dA4zTGAOEmzhWA/75rtO9bdH0pcBtKlVd7f1cCcwBOolI\nY+AYVf3MO2wScGKAMZvSVrDAL8He68cfd0Nv//IXuPHGYEI0xuwvzMQxH2grIq1EpBouOUwteJCI\ntAcaAHN92xqISHXveSPgJGApsBmoJyLtvEO7AV+HeA4mTAEX+E2ZAoMHw0UXwUMPBRSjMaaQ0Po4\nVDVXRG4GZgKVgQmqukREhgPZqhpJIn2BLFVV39sPB54WkXxcchsRGY0lIjcAr3v7NgPXhnUOJkQB\nF/gtWACXX+5W73v55YRmJjHGlED2/75OTRkZGZqdnV3WYZiILVvg5JNd8vj444R7r3/8EY4/HqpV\ng88+g2bNAorTmApORBZ4fc37scpxU7r8BX4zZiScNLZtc/NO7dwJ771nScOY0mCJw5Qef4HfxIkJ\nF/jl5sJll8HSpe5u15FHBhSnMaZYJd4JFpGaIvJ3ERnvvW4rIja3qImfv8Dv8ssTakrVTVY4cyY8\n+SR06xZQjMaYEsXShfgc8Ctwgvd6NXB/aBGZ1BRggV+kuaefhrvughtuCCA+Y0zMYkkcrVX1IeA3\nAFXdCRx4hZapeCZNCqzAD+CNN9zaGr17wwMPBBSjMSZmsSSOPSJSAzdHFF4F96+hRmVSx5w5rl8j\noAK/efOgf3/o0gVefNGG3RpTFmLpHL8HmAG0EJGJuGK8q8MMyqSIgAv8vv/eTVzYtClMnQo1agQT\npjEmPsUmDhERYBlwMW4yQQFuVdUNpRCbKc8CLvDbssVNkf7rr+4ipkmTYMI0xsSv2MShqioi01T1\nKODdUorJlHcBr+D3229w6aWu9GPmTDj88IDiNMYckFjuEH8uIseFHolJDQGv4KfqJiucNQvGjUu4\n9MMYE4BY+jiOB64QkR+AHbjbVaqqtsqB2V/ABX7gJit89lm4+2645poAYjTGJCyWxHFO6FGY1HDn\nna7A76GHEi7wA3jtNRg61C3KNHx4APEZYwJR4q0qVf0BqA+c7z3qe9uM2WfUKFejccstrkI8QXPn\nwpVXwkknwXPP2bBbY5JJLFOO3ApMBJp4j5dFZFDYgZlyZNIkuP12uOSSQAr8Vq6ECy+E9HR4662E\nR/EaYwIWy62q64DjVXUHgIg8iFt06YkwAzPlhL/A7+WXEy7w27zZDbvNzXXLvzZqFEyYxpjgxJI4\nBPCvBZ6HTTliABYvdiOoWrcO5NJgzx530fLdd24UVbt2Jb/HGFP6YkkczwGficib3utewLPhhWTK\nhZwc6N7dFfjNmAEHHZRQc6rwpz/B7NluZpJTTw0oTmNM4EpMHKr6qIjMAU72Nl2jql+EGpVJbpEC\nv23bAinwAzdZ4fPPw733urmojDHJq8TEISJ/AJao6ufe67oicryqfhZ6dCb5RAr8li93U4kcc0zC\nTWZmwt/+5hLGsGEBxGiMCVUsgxyfBLb7Xm/3tpmKJj8frrrKFfg9/zyceWbCTX7yCVx9tbs19cwz\nCQ/IMsaUglgSh6iqRl6oaj625GzFdOedbuhtQAV+337rLl5atnSzk1SvnniIxpjwxZI4VorILSJS\n1XvcCqwMOzCTZCIFfoMGBVLgt3GjG3YL8O67CfetG2NKUSyJYyBwIm7J2Bzc3FUDYmlcRLqLyHIR\nWSEiQ6PsHyUiC73HNyKyxbcvz7dvqm+7iMj/esd/LSK3xBKLSYC/wG/UqITvJ/36K1x0Efzwg1um\no02bgOI0xpSKWEZVrQP6xtuwiFQGxgLdcAlnvohMVdWlvrYH+44fBHTyNbFLVTtGafpqoAXQXlXz\nRcRWZghTpMDv5JMDKfBTheuuc4OxXnnFTSlijClfYply5CFvJFVVEXlfRNaLSCwDJrsAK1R1paru\nAbKAC4s5vh+QGUO7NwLDvb6WSGIzYfAX+AWwgh/Affe5iXPvvx/69QsgRmNMqYvlVtXZqroNOA/4\nHmgD3BnD+5oDq3yvc7xthYjIoUAr4APf5jQRyRaRT0Wkl297a6CPt2+6iLQtos0B3jHZ69evjyFc\ns59IgV/NmoEU+IFbI/y++9woqv/5n8RDNMaUjVgSR+R2Vk/gNVXdGkIcfYHJquqf2uRQVc0ALgce\nE5HW3vbqwG5v33hgQrQGVXWcqmaoakbjxo1DCDmF+Qv8pk8PpMDvww/h+uuha1d4+mkbdmtMeRZL\n4nhHRJYBnYH3RaQxsDuG963G9UVEpHvboulLgdtUqrra+7kSmMO+/o8c4A3v+ZuALSgVJH+B35tv\nBlLgt3y56wxv3Rpefx2qVQsgTmNMmYllPY6huFFVGar6G7CT4vsqIuYDbUWklYhUwyWHqQUPEpH2\nQAPcjLuRbQ1EpLr3vBFwEhDpVH8L6Oo9Pw34JoZYTCz8BX7PPRdIgd/69dCjB1Sp4obdNmgQQJzG\nmDIVUyGfqm7yPd+BW0K2pPfkisjNwEygMjBBVZeIyHAgW1UjSaQvkOUvMgQOB54WkXxcchvhG401\nApgoIoNxVezXx3IOJgb+Ar8rrki4ud273cXLTz+5yQt///sAYjTGlDnZ//s6NWVkZGh2dnZZh5Hc\nRo1ytRqDBsHo0Ql3QuTnu+LySZPcarKXXhpQnMaYUiMiC7z+5P3YgpzGfbMHWOAHbrLCSZNgxAhL\nGsakmiITh4icIyK9o2zvLSLdwg3LlJoPP3SLewdU4Aeue+R//9eNohoyJIAYjTFJpbgrjmHAh1G2\nzwGGhxKNKV2LF7vFvQMs8PvgAxgwAM46C/7v/2zYrTGpqLjEUV1VC1XOqeoGoFZ4IZlSkZPjajUC\nLPD7+mu4+GK35OvkyVC1agBxGmOSTnGjquqKSBVVzfVvFJGqQI1wwzKhihT4bd0a2Ap+a9e6Ybdp\naW7Ybb16AcRpjElKxV1xvAGMF5G9VxciUht4in0FeKa8iUxNG2CB365d7o7X2rUwdapbX8MYk7qK\nSxx/A9YCP4jIAhH5HPgvsN7bZ8qbSIHfnDmBFfjl57vJc+fNc5MXdumSeJjGmORW5K0q7xbVUBG5\nDzexIbjZbneVSmQmeEOGuDGyDz4YSIEfuMkKJ0+GRx5xFzLGmNRXZOIQkYsLbFKgvogsVNVfwg3L\nBO6xx2DkSFfgd2cskxuXbLYVLTwAABUHSURBVPx4l4MGDnRlIMaYiqG4zvHzo2w7CDhaRK5T1Q+i\n7DfJKFLgd/HFgRX4vfce3Hijm3n9iSds2K0xFUlxt6quibbdWzvjVdwSsibZRQr8TjopsAK/xYuh\nd2844gh356tKTDOeGWNSRdxTjqjqD4CN0C8PChb41Uh8FPXPP0PPnlCrFrzzDtStG0CcxphyJe6/\nFUXkMODXEGIxQfIX+E2fHkiB386dcP75sGGDK/9o0aLk9xhjUk9xneNv4zrE/Q4CfgdcGWZQJkEF\nC/wOPTThJvPyoH9/WLDAXbwce2wAcRpjyqXirjgeKfBagY3At6q6J7yQTEL8BX7TpwdS4AduJO+b\nb7oZ18+PNmzCGFNhFNc5Hm2CQ0TkZBHpp6o3hReWOSD5+XD11a7A7+WXAynwAzdZ4aOPupG8t9wS\nSJPGmHIspj4OEekEXA5ciqsetylHktGQIZCVFWiB37RpLmGcd54byWuMMcX1cbQD+nmPDcAk3IqB\nXYt6jylDkQK/m28OrMDvyy+hTx93tyszM5CRvMaYFFDcFccy4GPgPFVdAeCt822Sjb/A77HHAqnG\nW73aDbutVw/efhtq1w4gTmNMSiiujuNiYA0wW0TGi8iZgNUHJ5tIgd+JJwZW4Ld9u+sA37rVTZHe\nvHkAcRpjUkaRiUNV31LVvkB7YDZwG9BERJ4UkbNLK0BTjEiB3+9/7+YzD6DALy8P+vVzt6kmTQps\nUJYxJoWUWDmuqjtU9RVVPR9IB74A7go9MlO8EFbwA3fH65133PxTPXoE0qQxJsXENeWIqm5W1XGq\nGtM4TxHpLiLLRWSFiAyNsn+UiCz0Ht+IyBbfvjzfvqlR3vu4iGyPJ/6U4S/wmzYtkAI/gMcfd4/B\ng+HPfw6kSWNMCgptejoRqQyMBboBOcB8EZmqqksjx6jqYN/xg4BOviZ2qWrHItrOABqEEniyixT4\nLVvmCvw6Rv0nitvbb7uEceGF8PDDgTRpjElRcU9yGIcuuIWfVnqV5lnAhcUc3w/ILKlRLyE9DAwJ\nJMryxF/g99xzcNZZgTT7+efQty906uRW8bNht8aY4oSZOJoDq3yvc7xthXhTtbcC/Gt8pIlItoh8\nKiK9fNtvBqaq6prifrmIDPDen71+/foDO4Nk4y/w698/kCZXrXLFfQ0buquOWrVKfo8xpmJLlpUU\n+gKTVTXPt+1QVV0tIr8HPhCRRcAuXPX66SU1qKrjgHEAGRkZBSdrLH9CKPD75ReXNLZvh3//G373\nu0CaNcakuDATx2rAP/F2urctmr7AfnNfqepq7+dKEZmD6//YhVv/fIW4IreaIrJCVduQyl57LfAC\nv9xcVxW+ZImr1TjqqADiNMZUCGHeqpoPtBWRViJSDZccoo2Oao/r6J7r29ZARKp7zxsBJwFLVfVd\nVW2mqi1VtSWwM+WTxocfuttSARb4qbrJCqdPdxMYnnNOAHEaYyqM0K44VDVXRG4GZgKVgQmqukRE\nhgPZqhpJIn2BLFX13046HHhaRPJxyW2EfzRWhbFkCfTqFWiBH7iLliefdHe8BgwIpEljTAUi+39f\np6aMjAzNzs4u6zDik5MDJ5zgSrnnzg2sVuOtt9wdr4svdlNcVQrzmtMYU66JyAJVzSi4PVk6x43f\n1q2ubHvrVvjoo8CSRnY2XH45HHccvPiiJQ1jzIGxxJFsIgV+X38daIHfDz+4iQubNHF3vWrWDKRZ\nY0wFZIkjmUQK/GbPhpdeCqzAb+tWN+x21y54/31o2jSQZo0xFZQljmRy112uwG/EiMAK/H77DS69\ndN8MJR06BNKsMaYCs8SRLEaPhkcecQV+Q4KZTUUVbroJ3nsPnnkmsAsYY0wFZ92jyeC119wMgxdd\nFFiBH7g8NH48/PWvcN11gTRpjDGWOMrcRx/tK/ALcIbByZPdhUufPnD//YE0aYwxgCWOsrVkSeAr\n+AF89tm+1WSff96G3RpjgmVfKWVl9Wro3t0liwBX8Pvvf+GCC+Dgg12xX1paIM0aY8xe1jleFrZu\n3beCX4AFflu2QM+ebiTVtGnQuHEgzRpjzH4scZS2kAr89uyBSy6BFSvgX/+Cww4LpFljjCnEEkdp\nys+Ha64JvMBPFQYOhA8+gBdegNNPD6RZY4yJyvo4StNdd0FmZqAFfgD//KdbSXbYMPjjHwNr1hhj\norLEUVoiBX433RRYgR+4QvO773aTF957b2DNGmNMkSxxlIbJk/cV+I0eHViB37//7aa2OvlkmDAh\nsGaNMaZYljjCFlKB34oVrgTkkEPcsNvq1QNp1hhjSmSJI0yRAr9WrWDKlMAK/DZtcsNuVd164Q0b\nBtKsMcbExEZVhSVS4JeW5obdBvTtHhnN+/33MGsWtG0bSLPGGBMzSxxhKFjg17JlIM2qwg03uCYn\nToRTTgmkWWOMiYsljqD5C/ymTQuswA/gH/9w5R/Dh7tRVMYYUxYscQTJX+D34ovQrVtgTb/8Mtxz\nj6vT+NvfAmvWGGPiZp3jQYoU+P3zn2562oB89JFbT+P00936Gjbs1hhTlkJNHCLSXUSWi8gKERka\nZf8oEVnoPb4RkS2+fXm+fVN92yd6bS4WkQkiUjXMc4iZv8DvrrsCa/abb9ydr1at4PXXoVq1wJo2\nxpgDEtqtKhGpDIwFugE5wHwRmaqqSyPHqOpg3/GDgE6+JnaparQOgolAZL6OV4DrgScDDj8+IRX4\nbdjght1WquSG3QY087oxxiQkzCuOLsAKVV2pqnuALODCYo7vB2SW1KiqTlMPMA9IDyTaAxVSgd/u\n3dCrF6xa5UpAWrcOpFljjElYmImjObDK9zrH21aIiBwKtAI+8G1OE5FsEflURHpFeU9V4EpgRhFt\nDvDen71+/foDPYfihVTgpwrXXuumFHnhBZeTjDEmWSRL53hfYLKq5vm2HaqqGcDlwGMiUvBv7v8D\nPlLVj6M1qKrjVDVDVTMah7Gi0erVrlYj4AI/cKOnMjPhgQfcmuHGGJNMwkwcq4EWvtfp3rZo+lLg\nNpWqrvZ+rgTm4Ov/EJF7gMbA7cGFG4dIgd+WLS5pBFTgB+4K4x//cFccQwsNJzDGmLIXZuKYD7QV\nkVYiUg2XHKYWPEhE2gMNgLm+bQ1EpLr3vBFwErDUe309cA7QT1XzQ4w/On+B3+uvB1rgN3u2qww/\n80x46ikbdmuMSU6hJQ5VzQVuBmYCXwOvquoSERkuIhf4Du0LZHmd3RGHA9ki8iUwGxjhG431FNAU\nmOsN1R0W1jkU4i/wmzAh0AK/Zcvg4ouhTRs3SKtqcgwyNsaYQmT/7+vUlJGRodnZ2Yk3NGQIPPyw\nK/AL8D7S+vVw/PGwYwd8+qnrazfGmLImIgu8vub92JQjsXr8cZc0Ai7w27XLDcxaswbmzLGkYYxJ\nfpY4YjF5Mtx2W+AFfvn5bgW/uXPdrzj++ECaNcaYUCXLcNzk9fHHrsDvhBMCLfADN1nhq6/CQw/B\nJZcE1qwxxoTKEkdxli6FCy5ww22nTg2swA/g2WddV8mAAXDHHYE1a4wxobPEUZTIqklpaTBjRqAF\nfrNmwcCBcM45MHasDbs1xpQv1sdRFBHIyoLNmwMt8FuyxN2WOvxwd5uqin0Cxphyxr62itOihXsE\nZO1aN9ttzZrwzjtQt25gTRtjTKmxxFFKdu6E8893NRsffQSHHFLWERljzIGxxFEK8vPdwKzsbHjz\nTejcuawjMsaYA2eJoxTcdZdLGKNGuWI/Y4wpz2xUVcieemrfirK33lrW0RhjTOIscYRoxgy4+Wbo\n0QMee8yG3RpjUoMljpB89RVcdhkceaQb1WvDbo0xqcISRwh++skNu61Txw27rVOnrCMyxpjg2N/B\nAduxww273bzZTXOVnl7WERljTLAscQQoLw8uvxwWLoQpU6BTp5LfY4wx5Y0ljgDdcYebC/GJJ+C8\n88o6GmOMCYf1cQRkzBg3curWW91IKmOMSVWWOALw7rsuYZx/PowcWdbRGGNMuCxxJGjhQujTBzp2\nhFdeCXSdJ2OMSUqWOBKQk+OG3TZoAG+/DbVrl3VExhgTvlATh4h0F5HlIrJCRIZG2T9KRBZ6j29E\nZItvX55v31Tf9lYi8pnX5iQRqRbmORTll1/cralt29ytqoMPLosojDGm9IU2qkpEKgNjgW5ADjBf\nRKaq6tLIMao62Hf8IMA/gHWXqnaM0vSDwChVzRKRp4DrgCfDOIei5OZC376waJEr8Dv66NL87cYY\nU7bCvOLoAqxQ1ZWqugfIAoqbG7YfkFlcgyIiwBnAZG/TC0CvAGKNmSrcdhtMm+aG3XbvXpq/3Rhj\nyl6YiaM5sMr3OsfbVoiIHAq0Aj7wbU4TkWwR+VREIsmhIbBFVXNLajMsjz/u1gn/y1/gxhtL8zcb\nY0xySJYCwL7AZFXN8207VFVXi8jvgQ9EZBGwNdYGRWQAMADgkICW25syBQYPhosugoceCqRJY4wp\nd8K84lgN+BfsTve2RdOXArepVHW193MlMAfX/7ERqC8ikYRXZJuqOk5VM1Q1o3Hjxgd6DnstWOCm\nE8nIgJdfhko2Hs0YU0GF+fU3H2jrjYKqhksOUwseJCLtgQbAXN+2BiJS3XveCDgJWKqqCswGenuH\nXgVMCfEcAPjxRzeFSKNGbkqRmjXD/o3GGJO8QkscXj/EzcBM4GvgVVVdIiLDReQC36F9gSwvKUQc\nDmSLyJe4RDHCNxrrLuB2EVmB6/N4NqxzADfc9rzzYOdON+y2WbMwf5sxxiQ/2f/7OjVlZGRodnZ2\n3O/LzXVJY9YsmD4dunULIThjjElSIrJAVTMKbk+WzvGko+omK5w5E8aNs6RhjDER1sVbjPbt4a9/\nhRtuKOtIjDEmedgVRxFEXKGfMcaY/dkVhzHGmLhY4jDGGBMXSxzGGGPiYonDGGNMXCxxGGOMiYsl\nDmOMMXGxxGGMMSYuljiMMcbEpULMVSUi64EfDvDtjYANAYZTllLlXFLlPMDOJVmlyrkkeh6Hqmqh\ndSkqROJIhIhkR5vkqzxKlXNJlfMAO5dklSrnEtZ52K0qY4wxcbHEYYwxJi6WOEo2rqwDCFCqnEuq\nnAfYuSSrVDmXUM7D+jiMMcbExa44jDHGxMUShzHGmLhY4vARkcoi8oWIvBNlX3URmSQiK0TkMxFp\nWfoRxqaE87haRNaLyELvcX1ZxBgLEfleRBZ5cRZaNF6cx73P5CsRObYs4oxFDOdyuohs9X0uw8oi\nzliISH0RmSwiy0TkaxE5ocD+cvG5xHAe5eIzEZHDfDEuFJFtInJbgWMC/UxsBcD93Qp8DdSNsu86\nYLOqthGRvsCDQJ/SDC4OxZ0HwCRVvbkU40lEV1UtqoDpXKCt9zgeeNL7mayKOxeAj1X1vFKL5sCN\nBmaoam8RqQbULLC/vHwuJZ0HlIPPRFWXAx3B/dEIrAbeLHBYoJ+JXXF4RCQd6Ak8U8QhFwIveM8n\nA2eKiJRGbPGI4TxSyYXAi+p8CtQXkd+VdVCpTETqAacCzwKo6h5V3VLgsKT/XGI8j/LoTOA7VS04\nU0agn4kljn0eA4YA+UXsbw6sAlDVXGAr0LB0QotLSecBcIl3uTpZRFqUUlwHQoF/icgCERkQZf/e\nz8ST421LRiWdC8AJIvKliEwXkSNKM7g4tALWA895t0OfEZFaBY4pD59LLOcB5eMz8esLZEbZHuhn\nYokDEJHzgHWquqCsY0lEjOfxNtBSVY8G3mPfVVQyOllVj8VdZt8kIqeWdUAJKOlcPsfNC3QM8ATw\nVmkHGKMqwLHAk6raCdgBDC3bkA5ILOdRXj4TALzbbRcAr4X9uyxxOCcBF4jI90AWcIaIvFzgmNVA\nCwARqQLUAzaWZpAxKPE8VHWjqv7qvXwG6Fy6IcZOVVd7P9fh7tl2KXDI3s/Ek+5tSzolnYuqblPV\n7d7zaUBVEWlU6oGWLAfIUdXPvNeTcV/AfuXhcynxPMrRZxJxLvC5qq6Nsi/Qz8QSB6Cqf1XVdFVt\nibvU+0BV+xc4bCpwlfe8t3dMUlVPxnIeBe5rXoDrRE86IlJLROpEngNnA4sLHDYV+KM3YuQPwFZV\nXVPKoZYolnMRkWaRPjMR6YL7fzPZ/jBBVX8GVonIYd6mM4GlBQ5L+s8llvMoL5+JTz+i36aCgD8T\nG1VVDBEZDmSr6lRcJ9pLIrIC2IT7Yi4XCpzHLSJyAZCLO4+ryzK2YjQF3vT+v60CvKKqM0RkIICq\nPgVMA3oAK4CdwDVlFGtJYjmX3sCNIpIL7AL6JtsfJj6DgInerZGVwDXl9HMp6TzKzWfi/UHSDfiT\nb1ton4lNOWKMMSYudqvKGGNMXCxxGGOMiYslDmOMMXGxxGGMMSYuljiMMcbExRKHMQWISEPfTKM/\ni8hq3+tqIf3OKiJywHMlicjtIpIWRFvGlMSG4xpTDBG5F9iuqo8U2C64/3+KmxMsnt9TBdigqvUP\n8P05wJGquiXRtowpiV1xGBMjEWkjIktFZCKwBPidiJwrInNF5HNx67XU8o49TkQ+9CY1nC4iTaO0\n11rc2i6LgPsK7BsqIvO8ySiH+X7/EhHJErd+xKsiUkNEBgNNgI9FZJavjRHeBH1zRaRJiP80poKx\nxGFMfNoDo1S1A/AbbmK8M70JDL8CbhWR6ri1Hi5R1c7Ay8A/orT1BDBaVY8C1kU2ikgP4BDcegkd\ngRNF5ERvdwfgMVU9HNgN/ElVR3nvP0VVz/KOqwd86E3QNxe4NrB/AVPh2ZQjxsTnO1WNrOB3Iu6L\n/D/edCLVgE+Aw4EjgFne9sq4SfUKOgE433v+EvuuOs7GTVj3hfe6NtAOlxz+662nAC4hDcBNpV/Q\nLlWd7j1fAJwS11kaUwxLHMbEZ4fvueBWkLvSf4CIdAK+UtVYvqyjdTIKcL+qPlug3TZRji+qk3KP\n73ke9v+6CZDdqjLmwP0HOE1Efg97Z8Fti5tltbk3oyoiUq2IRYDmApd5z6/wbZ8JXOfrL0n3Tefd\nSkSO855fjrvCAfgFqBPQeRlTLEscxhwgb92D64BJIvIlLpG089Y76Q08KiJf4W45RVvf+RZgsHfM\n3s5zb+2HycCnXsf5q7jbVeCmwb9dRL7GrZE9zts+DndrbG/nuDFhseG4xpQT3q2qyarasaxjMRWb\nXXEYY4yJi11xGGOMiYtdcRhjjImLJQ5jjDFxscRhjDEmLpY4jDHGxMUShzHGmLj8P7zwr3EJlrov\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NWGuiC0C9a5",
        "colab_type": "code",
        "outputId": "badd01e2-2f05-4713-8404-2cbd6bf4baeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "min_samples_splits = np.linspace(0.6, 0.7,4, endpoint=True)\n",
        "train_results = []\n",
        "test_results = []\n",
        "for min_samples_split in min_samples_splits:\n",
        "   dt = DecisionTreeClassifier(max_depth=5.5,min_samples_split=min_samples_split)\n",
        "   dt.fit(X_train_res, y_train_res)\n",
        "   train_pred = dt.predict(X_train)\n",
        "   false_positive_rate, true_positive_rate, thresholds =    roc_curve(y_train, train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = dt.predict(X_test)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   test_results.append(roc_auc)\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(min_samples_splits, train_results, 'b', label=\"Train AUC\")\n",
        "line2, = plt.plot(min_samples_splits, test_results, 'r', label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('AUC score')\n",
        "plt.xlabel('min samples split')\n",
        "plt.show()\n",
        "## Min_Samples_Splits=0.67"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ZND/pkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXRzgdcII2-i",
        "colab_type": "code",
        "outputId": "bf722fe4-15b3-46e2-d558-2be2e82565aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "max_depths = np.linspace(1, 15, 15, endpoint=True)\n",
        "train_results = []\n",
        "test_results = []\n",
        "for max_depth in max_depths:\n",
        "   dt = DecisionTreeClassifier(max_depth=max_depth)\n",
        "   dt.fit(X_train_res, y_train_res)\n",
        "   train_pred = dt.predict(X_train)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   # Add auc score to previous train results\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = dt.predict(X_test)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   # Add auc score to previous test results\n",
        "   test_results.append(roc_auc)\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
        "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel(\"AUC score\")\n",
        "plt.xlabel(\"Tree depth\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9b3/8dcnG2FHICirQRYRN5a4\na11RXIre3lah1bbYltrbamvrtfprq1Z7u9zeXmsrt9bWrdWCXq2WupSiVa9WlB2UTRJECCKEEPZA\nts/vj3MCwzBJJjCTM0nez8fjPDLnzJkzn4k473y/53u+x9wdERGReFlRFyAiIplJASEiIgkpIERE\nJCEFhIiIJKSAEBGRhHKiLiBVevfu7YWFhVGXISLSqsyfP3+zuxckeq7NBERhYSHz5s2LugwRkVbF\nzD5s6Dl1MYmISEIKCBERSUgBISIiCSkgREQkIQWEiIgkpIAQEZGEFBAiIpJQm7kOQjLUwoWwezcc\ncQT07Bn87NAh6qoyQl0d7Nlz6MvevZCO2frNIC8PcnMP/JloWzLPxf7Mzg4Ws9TXLamngJD0+dGP\n4Ac/OHh7x45BUNQv9cERv8Rsr+t+BNuzj2DLzjzKy2Hbtv1fknv3QlXV/sfxS0PPJdpeW5v4oyT6\nQmvoSy7R9urqg7/gq6uT/1U2JB1ftC1xi5j6oMjJCZZEj5N9Pj8fOnUKls6d9z9uaGlon7w8BVc8\nBYSknjvceSfccw987nNw3XVQUQEVFdRt3sKejyuo3lhB7eYKfEsFtvZDcrcvJG93BR2qdiY8ZBbQ\nA8ilE7n0pBPdqCGHOrIaXcwMsrIOXLKzsNjH4bplZ+HZOdRk5e1bqmMe12blUW15Bzx/wD4JnqsJ\nX7Oncy+qu/cmv6ORn88hLx077n+cm5u+gKipCQK0ujr4Gfs4/mdjz8XvU1sbHDv+ZzKPE23bswfK\ny4NGauxSWdn8z52VdWCIdOkCXbvu/xm7JLOtS5cgdFqztAaEmY0H7gOygd+7+0/jnr8XOD9c7QT0\ncfce4XODgN8DAwEHLnP3NemsV1LAHW6/HX72MyonXc/1VQ9S/P1stmyBLVtg69bGX967ezWFPbYy\nqGsF/TtV0C9/C0fmVdA7p4KeVkGPugq61lRwZPU2sq2OLKsjuz4O7MB4MK/D6uqgrjroz6mrC+qr\nf5xoqa4Olsqq/d9s9U2Nw9WhA/TvHywDBgTLEQMOXD/qqOBP4wiZBeGTmxtpGYelri4IifjgiF12\n7Wr8uZ07YceO4N/sunXB4/ptDbU04+XlHRganTsf3CXXVFddMo9794azz0797zFtAWFm2cBUYBxQ\nCsw1sxnuvqx+H3e/OWb/G4HRMYf4A/Af7j7LzLoAdemqVVLEHb7zHbj3Xiq/cAOnzZtK8eoszjsP\njj026DFKtPTqFfzs3h1ycnKBgnDJIO7Bt0JVVeNLfd9V/LbNm6G0FNavD36+8w4880zwfKzs7CAk\n6gNjQFyADBgA/frpPE4TsrKCL+POnVN/bPeg5RIbGLFLY9t27Qr+k+/efXDrq6GWVzJdfqedBm+/\nnfrPms4WxKlAsbuvBjCz6cCVwLIG9p8E3BnuOxLIcfdZAO6euN9BMkddHdx0E0ydSuVXbuK02b9k\nVYnxwgtwwQVRF5cCZvs7wTt1Ss0x3YP+kdLS/Ut9gJSWwtKlMHNm8O0Sr6AgCIqcnMZbRPFLUy2o\nurrgmP37w6BB+5eBA/c/7t+/9fedHAazoKuvY0fo0yf97xf7d0miMKmqSt/fC+kMiP7Aupj1UuC0\nRDua2dHAYOAf4abhwFYz+3O4/WXgNnevjXvdFGAKwKBBg1JavDRDXR187Wvw4INU/tt3OOPNn7Oq\n2PjrX9tIOKSLWdA30Ls3jBrV8H7btycOkA0bgt99/DmWxpZE52Til717g+OvWwdz5watn/i6jzoq\ncXjUPy4o0BnfFMnO3h9ILS1TTlJPBJ6OCYAc4ByCLqe1wJPAF4GHYl/k7g8CDwIUFRW1wNgLOUht\nLXz5y/Doo1R+63bOfPU/WLHSmDEDLroo6uLaiG7dYOTIYInC7t1BWKxbB2vXBkv948WL4fnnDz4r\nnJ8fdIfFtkKOPLLpM7w5mfKVJJDegFhPcIK53oBwWyITga/HrJcCi2K6p54DTicuICRiNTXwhS/A\nn/5E5Xfv4qyZd7BsufGXv8DFF0ddnKRMp07BSaRjj038fH1XWWxwxAbJrFnw0UfJdabn5zdvqFD9\nmd/YpX4YUv3SjrvDDlc6A2IuMMzMBhMEw0Tgs/E7mdkI4Ahgdtxre5hZgbuXARcAuhtQJqmuhmuv\nhaeeovL7/8E5L/0/li6DZ5+F8eOjLk5aVGxX2Zgxifeprg6GsTV1NjfR9s2bYc2aA7c152KN+vNG\nTQVJ7LYuXYJRE4mu1YmiryciaQsId68xs28AMwmGuT7s7kvN7G5gnrvPCHedCEx33/9f3N1rzewW\n4BUzM2A+8Lt01SrNVFUFEyfCs89SeffPOfevt7BkSRAOl10WdXGSkXJzgy6mI488/GO5B91e9WFR\nP1511679S/x6Q9s2bTr4+abGsHbokPjCzmSWjh1b1bkZ85a4bLIFFBUVuW452gL27oVPfxqef57K\nn97H+c/exIIFwYjNT34y6uJEDpN78AfQzp3BBRDhBZ6NLlu27H+8bVvjx8/NTa4F09xtXboc8phe\nM5vv7kWJntMZIUleZSX8y7/AzJlU/vdvuOCpG5g/H55+WuEgbYRZ0ELo0CG4QKe5amuDkGgoTLZu\nTdyS2bYtOE8T3+JJ9g/4U06BOXOaX28TFBCSnF27YMIEePVVKqc+xEVPXM+8efDUU3DllVEXJ5Ih\nsrP3XwF6uOqvyEum6ywV75eAAkKatmMHXHEFvPkme377GBf/4TreeQeefDJoUIhIGsRekde7dyQl\nKCCkcdu3w6WXwjvvsOf3j3PxI5OYPRumTYN//deoixORdFJASMMqKoIxqwsWsOexJxn/u3/ln/+E\nP/0JPvOZqIsTkXRTQEhi5eXB1W7vvsvePz3DZb+ZwBtvwOOPwzXXRF2ciLQEBYQcrKwsmCdj5Ur2\nTH+Oy6dexuuvwx/+AJMmRV2ciLQUBYQc6OOP4cILYfVq9j79Vz553zhefRUeeyy494+ItB9ZURcg\nGWT9ejjvPFizhqrnXmTCr8fxyivwyCPBTeFEpH1RQEhwcc/q1XDuubB+PXtnzOTKX57PrFnw0EPB\nfHwi0v6oi6m1qawMplhO5r6Jyd5rsf52mt26UfXCLD71s9P529/g97+HyZOj/bgiEh0FRGuydCl8\n6lPw/vuN75efv//u6/FL794NPld18RV86nvH8eKL8OCD8KUvtczHEpHMpIBoLaZPD76xu3ULLkTo\n3//AL/j6Cbzy8w/ppvdVVcEcfC+8AA88AF/5Sho+g4i0KgqITFddDbfeCr/8JZx1Fvzv/0Lfvkm/\nvKYmmGyyvDzxsnlz8HPVqqCB8j//A1/9aho/j4i0GgqITLZhA1x9Nbz5Jnzzm/Dzn1NNLssW7/9i\nT/RlH7ts3drw4XNzgwkr65dHHoEvfrHFPp2IZDgFRKZ6881gPovt24MupUmTWLcumDl14cKDd+/S\nZf8Xfe/eMGTIgV/+sc/VP+7SpVXdu0REWpgCItO4w69+BbfcAoMHB/fzPeEEZs8OZk6trITf/haG\nD9//Zd+zZzB9vYhIKikgMsnOncHZ4enTg6bCY49B9+489hhMmQIDB8Krr8Jxx0VdqIi0B7pQLlO8\n/z6cfnpwB56f/AT+/Gdqu3TnlluC8wLnnBPcMErhICItRS2ITPDss8Hlyh06wMyZcNFFbNsWTIz3\n0kvw9a/DvfcGJ5VFRFqKWhBRqqmB228PLn4bMQLmz4eLLmLVqqAxMWtWcE3C/fcrHESk5akFEZWy\nsqCJ8MorwYUH990HHTrwyivB4KWsrCAgzjsv6kJFpL1SCyIKc+bAmDHBUNaHH4YHHsDzOnD//XDJ\nJcFF0nPmKBxEJFoKiJbkHoxRPeccyMmBt96CyZOpqoIbboAbb4TLLgs2H3NM1MWKSHungGgplZVw\n/fVBElxwQXC+YcwYNm+GceOCyfFuvx2eew66do26WBERnYNoGR98EJyIXrQI7rwT7rgDsrJ4912Y\nMCGYUeOJJ+Czn426UBGR/RQQ6fbSS8G9Ot3h+efh8ssB+Mtf4Nprg9bCG2/AKadEXKeISBx1MaVL\nXR388IdBIAwaFHQpXX457vDjHwfTZhx3HMybp3AQkcykgEiXv/4V7roraCaEZ50rK4PGxPe+F4xw\nff116Ncv6kJFRBJLa0CY2XgzW2lmxWZ2W4Ln7zWzReHyvpltjXu+m5mVmtn96awzLZYsCX7+9rfQ\nqRPr18MnPhFMs/STn8Djj0PHjtGWKCLSmLSdgzCzbGAqMA4oBeaa2Qx3X1a/j7vfHLP/jcDouMPc\nA/xfumpMq5KSoHnQsSNz5sBVV8GOHcEopQkToi5ORKRp6WxBnAoUu/tqd68CpgNXNrL/JGBa/YqZ\njQWOBP6exhrTp6QEhgzhiSeClkOHDjB7tsJBRFqPdAZEf2BdzHppuO0gZnY0MBj4R7ieBfwCuKWx\nNzCzKWY2z8zmlZWVpaToVPGSEuZtHcK11wbzKs2dCyecEHVVIiLJy5ST1BOBp929Nlz/N+BFdy9t\n7EXu/qC7F7l7UUFBQdqLTNru3diGDTz77lCmTIG//z24uY+ISGuSzusg1gMDY9YHhNsSmQh8PWb9\nDOAcM/s3oAuQZ2Y73f2gE90ZafXq4AdDeOQ+yMuLuB4RkUOQzoCYCwwzs8EEwTAROOhaYTMbARwB\nzK7f5u6fi3n+i0BRqwkHCM4/ADuPHEJ+fsS1iIgcorR1Mbl7DfANYCawHHjK3Zea2d1mFnuqdiIw\n3d09XbW0uDAgco4dEnEhIiKHLq1Tbbj7i8CLcdvuiFu/q4ljPAo8muLS0qu4mK3Wg6NG9oy6EhGR\nQ5YpJ6nblOoVJRT7EIYNi7oSEZFDp4BIg9pVJZSggBCR1k0BkWo1NeRt+FABISKtngIi1dauJau2\nhtU2VHeFE5FWTQGRajFDXHX9g4i0ZgqIVAsDInu4hriKSOumO8qlmK8qZi8d6HmCbvQgIq2bWhAp\nVrW8hNUcw9Dh+tWKSOumb7EUq3k/GOI6fHjUlYiIHB4FRCq5k1e6WkNcRaRNUECk0saN5O7dxQdZ\nQyksjLoYEZHDo4BIpXAE066jhpCj0/8i0sopIFIpDAgbqiGuItL66e/cFPJVxdSRRbeTCqMuRUTk\nsCkgUqhyaQmbGMgxI3QJtYi0fupiSqGaFZrFVUTaDgVECuWuU0CISNuhgEiV7dvpuHMza7KHMmhQ\n1MWIiBw+BUSqxMzimp0dcS0iIimggEgVDXEVkTZGAZEidcVBQHQ+SQEhIm2DhrmmyO7FxeymgKNP\n6Bp1KSIiKaEWRIpUa4iriLQxCogUyVmrgBCRtkUBkQp799J5yzrWZA+lf/+oixERSQ0FRCqsWUMW\nzq6jhpCl36iItBH6OkuFcIgrQzSCSUTajiYDwsw6mdkPzOx34fowM7si/aW1HnWrgoDodKICQkTa\njmRaEI8Ae4EzwvX1wI/SVlErtGNRMTvpTN+T+0RdiohIyiQTEEPc/T+BagB33w1YMgc3s/FmttLM\nis3stgTP32tmi8LlfTPbGm4fZWazzWypmS0xs2ua8ZlaXNWycATT8KR+LSIirUIyF8pVmVlHwAHM\nbAhBi6JRZpYNTAXGAaXAXDOb4e7L6vdx95tj9r8RGB2u7gY+7+6rzKwfMN/MZrr71iQ/V4vK/rCE\nEo7jdA1xFZE2JJkWxJ3A34CBZvYE8ApwaxKvOxUodvfV7l4FTAeubGT/ScA0AHd/391XhY8/AjYB\nBUm8Z8urq6Pr5g/4MHcofftGXYyISOo02oIwMwNWAJ8CTifoWvqmu29O4tj9gXUx66XAaQ28z9HA\nYOAfCZ47FcgDShI8NwWYAjAoqjm2168nt3YvO/sOwdTDJCJtSKMtCHd34EV3L3f3F9z9+STDobkm\nAk+7e23sRjPrC/wRmOzudQnqe9Ddi9y9qKAgogZG/RDXYzSCSUTalmS6mBaY2SmHcOz1wMCY9QHh\ntkQmEnYv1TOzbsALwPfc/e1DeP8WUft+EBAdT1BAiEjbksxJ6tOAz5nZh8Augm4md/eTmnjdXGCY\nmQ0mCIaJwGfjdzKzEcARwOyYbXnAs8Af3P3pZD5IVLYtLKErORSMGdj0ziIirUgyAXHJoRzY3WvM\n7BvATCAbeNjdl5rZ3cA8d58R7joRmB52Z9W7GvgE0MvMvhhu+6K7LzqUWtJp73vFlFPI0BGaOV1E\n2hY78Hu5gZ3MTgbOCVffcPfFaa3qEBQVFfm8efNa/H03DRzLgtICxmz8G310nZyItDJmNt/dixI9\nl8xUG98EngD6hMvj4TUL4k6XTSWsyx1CVOfIRUTSJZl+kS8Bp7n7LgAz+xnB+YJfp7OwVmHLFjpV\nbWPHgKEa4ioibU4yo5gMiB1+WkuSU220eeEQ17rBGsEkIm1PMi2IR4B3zOzZcP0q4KH0ldR61Kws\nIQfoMFIBISJtT5MB4e7/bWavAWeHmya7+8K0VtVKVMwroQDodcoxUZciIpJyTQaEmZ0OLHX3BeF6\nNzM7zd3fSXt1GW7Pe8Wspx/HHN8x6lJERFIumXMQvwF2xqzvDLe1e/ZBOM23ZnEVkTYoqZPUsRex\nhXMi6aowoMvGEkrzhtCrV9SViIikXjIBsdrMbjKz3HD5JrA63YVlvN276bF7A9v7DI26EhGRtEgm\nIG4AziSYT6l+yu4p6SyqVVgdZGRtoUYwiUjblMwopk0E8yVJjKrlJeShIa4i0nYlM9XGf4Yjl3LN\n7BUzKzOza1uiuEy2ZW5wkdwRRQoIEWmbkuliutjdtwNXAGuAocC/p7Oo1mD3u8VU0IOjR/eMuhQR\nkbRIJiDqu6EuB/7X3belsZ5Ww0o0xFVE2rZkAuJ5M1sBjAVeMbMCYE96y8p8nTeWUNphCN27R12J\niEh6NBkQ7n4bwSimInevBnYDV6a7sIxWU0PPHR+yrbeGuIpI25XUBW/uviXm8S6CW4+2X2vXkuM1\n1BytE9Qi0nYl08UkcSqXBiOY8o5TQIhI26WAOATl7wQB0WOsAkJE2q4GA8LMLjGzTyfY/mkzG5fe\nsjLbriUl7KEDA07tF3UpIiJp01gL4g7g9QTbXwPuTks1rUVJMas5hqHD1QATkbarsW+4Du5eFr/R\n3TcDndNXUubrtKGE9R2G0LVr1JWIiKRPYwHRzcwOGuVkZrlA+71Djju9tq2mQkNcRaSNaywg/gz8\nzsz2tRbMrAvwQPhc+7RxI53qdlE9SCeoRaRtaywgvg9sBD40s/lmtgD4ACgLn2uXdi0Jh7iOUECI\nSNvW4IVy7l4D3GZmPySYoA+g2N0rW6SyDLVpdgmDge5jFBAi0rY1GBBm9qm4TQ70MLNF7r4jvWVl\nrl1LSqgli35nFkZdiohIWjU21cYnE2zrCZxkZl9y93+kqaaM5sXFrGMgx4zIi7oUEZG0aqyLaXKi\n7WZ2NPAUwa1H252OHwWzuBZ2iroSEZH0avaVXu7+IZCbhlpahV5bS6jopSGuItL2NTsgzOxYYG+S\n+443s5VmVmxmtyV4/l4zWxQu75vZ1pjnvmBmq8LlC82tMy22b+eIms1UDdAJahFp+xo7Sf1XghPT\nsXoCfYHrmjqwmWUDU4FxQCkw18xmuPuy+n3c/eaY/W8ERoePewJ3AkVhDfPD11Yk+bnSYvvCEroB\nOccqIESk7WvsJPV/xa07UA6scveqJI59KsGw2NUAZjad4EZDyxrYfxJBKABcAsyqvw+Fmc0CxgPT\nknjftNn4VhAQ3UYrIESk7WvsJHWiifows7PNbJK7f72JY/cH1sWsl9LAie3wxPdgoH5kVKLX9k/w\nuinAFIBBgwY1Uc7h27k4uEiu79kKCBFp+5I6B2Fmo83s52a2BrgHWJHiOiYCT7t7bXNe5O4PunuR\nuxcVFBSkuKSD1a0qYRMFDD5Js/SJSNvX2DmI4QTdPpOAzcCTgLn7+Ukeez0wMGZ9QLgtkYlAbItk\nPXBe3GtfS/J90yZ/fTGlHYbQp0PUlYiIpF9jLYgVwAXAFe5+trv/GmjOX/hzgWFmNtjM8ghCYEb8\nTmY2AjgCmB2zeSZwsZkdYWZHABeH2yLVs6KEiiPUvSQi7UNjAfEpYAPwqpn9zswuBCzZA4dzOX2D\n4It9OfCUuy81s7vNbELMrhOB6e7uMa/dQtCVNTdc7q4/YR0V37OXI6vWsWeAroEQkfahsZPUzwHP\nhdN9Xwl8C+hjZr8BnnX3vzd1cHd/EXgxbtsdcet3NfDah4GHm3qPllKxcA09cbKHqwUhIu1Dkyep\n3X2Xu//J3T9JcC5gIfDdtFeWYT7+ZzCCSUNcRaS9aNaV1O5eEY4cujBdBWWqHYuCgDjyTAWEiLQP\nzZ5qo72qfb+EnXRmUFGfqEsREWkRCogkdSgtZl3eEHLzkj5PLyLSqikgktRzSwlbNMRVRNoRBUQS\nvLaOvns/oLK/hriKSPuhgEhC2aL15LOXrGFqQYhI+6GASEL9ENeuJysgRKT9UEAkYdtCDXEVkfZH\nAZGEmpUlVJNDv9MGNr2ziEgboYBIQoe1xazPLSQnv7H7K4mItC0KiCT0KC+hvIe6l0SkfVFANKGu\n1um3p4TKfhriKiLtiwKiCR8v20IPtmFD1YIQkfZFAdGEj94IRjB1PkkBISLtiwKiCdsWBAHR5wwF\nhIi0LwqIJlSvCALiqDOPibgSEZGWpYBoQu7aEjbm9COrc8eoSxERaVEKiCb02FzM5u7qXhKR9kcB\n0Yi6OuhbWcKuvhriKiLtjwKiEaXv76YfG7AhakGISPujgGjE+jdWAxriKiLtkwKiEVvnByOYep+m\ngBCR9kcB0Yi9y4OAKDhdASEi7Y8CohE5H5awPbsH1qtn1KWIiLQ4BUQjupcVU9ZVrQcRaZ8UEA2o\nqYG+u0vYdZQCQkTaJwVEAz4sqeFoPsSH6BoIEWmfFBANKH1rLbnU0PEEtSBEpH1Ka0CY2XgzW2lm\nxWZ2WwP7XG1my8xsqZn9KWb7f4bblpvZr8zM0llrvIp5wQimXqcqIESkfUrbTZbNLBuYCowDSoG5\nZjbD3ZfF7DMMuB04y90rzKxPuP1M4CzgpHDXN4FzgdfSVW+8vcuCgOh5igJCRNqndLYgTgWK3X21\nu1cB04Er4/b5CjDV3SsA3H1TuN2BfCAP6ADkAhvTWOtBsteUsNc6YP37teTbiohkjHQGRH9gXcx6\nabgt1nBguJn908zeNrPxAO4+G3gV2BAuM919efwbmNkUM5tnZvPKyspSWnzXshLKuh4DWTpNIyLt\nU9TffjnAMOA8YBLwOzPrYWZDgeOAAQShcoGZnRP/Ynd/0N2L3L2ooKAgZUVVV0PfXcXsPFLdSyLS\nfqUzINYDA2PWB4TbYpUCM9y92t0/AN4nCIx/Ad52953uvhN4CTgjjbUe4IPVzjGspm6whriKSPuV\nzoCYCwwzs8FmlgdMBGbE7fMcQesBM+tN0OW0GlgLnGtmOWaWS3CC+qAupnRZO3cjXdilIa4i0q6l\nLSDcvQb4BjCT4Mv9KXdfamZ3m9mEcLeZQLmZLSM45/Dv7l4OPA2UAO8Ci4HF7v7XdNUar3yORjCJ\niKRtmCuAu78IvBi37Y6Yxw58O1xi96kFvprO2hqzZ2kQEN1GKyBEpP2K+iR1Rsr6oIRasrDBhRFX\nIiISHQVEAl02lbCl80DIy4u6FBGRyCgg4uzZEwxx3dFH3Usi0r4pIOKsXg1DKKG2UENcRaR9U0DE\n+WDxdgrYTIfj1YIQkfZNARFn3xDXIgWEiLRvaR3m2hpVvhcERJeTFRAiUaqurqa0tJQ9e/ZEXUqb\nkJ+fz4ABA8jNzU36NQqIOLY6CAiGKCBEolRaWkrXrl0pLCykhW8H0+a4O+Xl5ZSWljJ48OCkX6cu\npjidN5awPb8AunaNuhSRdm3Pnj306tVL4ZACZkavXr2a3RpTQMTYvRuO2lXC9gK1HkQygcIhdQ7l\nd6mAiFFcDEMppuZoDXEVEVFAxChZtpeBrKPDSLUgRNqz8vJyRo0axahRozjqqKPo37//vvWqqqqk\njjF58mRWrlzZ7Pe+4oorOPvssw/Ydu211/Lcc8/tW6+pqaFHjx771lesWMGll17KsGHDGDNmDBMn\nTmTTpk0cLp2kjlE2dw1ZOD3GKiBE2rNevXqxaNEiAO666y66dOnCLbfccsA+7o67k9XAXScfeeSR\nZr/vli1bWLJkCfn5+axdu5ZBgwY1+Zrdu3dz+eWX8+tf/5rLLrsMgFdeeYXy8nL69OnT7BpiKSBi\n7H43GMGk+0CIZK5vfQvC7+5mGzUKfvnLQ3/v4uJiJkyYwOjRo1m4cCGzZs3ihz/8IQsWLKCyspJr\nrrmGO+4IJqw+++yzuf/++znhhBPo3bs3N9xwAy+99BKdOnXiL3/5S8Iv76effpqrrrqK7t27M336\ndG699dYma3r88cc599xz94UDwIUXXnjoHzKGuphilWiIq4g0bsWKFdx8880sW7aM/v3789Of/pR5\n8+axePFiZs2axbJlyw56zbZt2zj33HNZvHgxZ5xxBg8//HDCY0+bNo1JkyYxadIkpk2bllQ97733\nHmPHjj2sz9QQtSBidP64hD05nck/zGaZiKTP4bQAUmHIkCEUFRXtW582bRoPPfQQNTU1fPTRRyxb\ntoyRI0ce8JqOHTty6aWXAjB27FjeeOONg4770UcfsXbtWs44I7i7cl1dHStWrGDEiBEJRyC1xAgv\ntSBCO3bAUbtL2NZ7CGhonYg0oHPnzvser1q1ivvuu49//OMfLFmyhPHjxye81iAv5tYB2dnZ1NTU\nHLTPk08+yebNmyksLKSwsJC1a9fua0X06tWLioqKfftu2bKF3r17A3D88cczf/78lH2+WAqIUP0Q\n12oNcRWRJG3fvp2uXbvSrVs3NmzYwMyZMw/5WNOmTePll19mzZo1rFmzhjlz5uwLiPPOO4/p06dT\nXV0NwKOPPsr5558PwHXXXa0XabAAAAyfSURBVMdrr73G3/72t33HevXVV1m+fPlhfLKAuphCq1bW\nMYEP2D7ik1GXIiKtxJgxYxg5ciQjRozg6KOP5qyzzjqk45SUlLBhw4YDuq6GDRtGfn4+8+fP56qr\nrmLBggWMHTuWrKwshg0bxgMPPABAp06deP7557n55pu58cYbyc3NZdSoUdx3332H/fksuC1061dU\nVOTz5s075Nf/6t/XcdN/DWLvfQ/Q4abIboctIqHly5dz3HHHRV1Gm5Lod2pm8929KNH+6mIK1Q9x\n1UVyIiIBBUTIizXEVUQklgIi1PGjEmotBwYOjLoUEZGMoIAAtm6FvpUlbO9ZCDk6by8iAgoIAFat\nCoa4Vg1S95KISD0FBLDqfWcIJeSM0DUQIiL1FBBA6ZIt9GAb3UapBSEiqZnuG+Dhhx/m448/bvD5\nqqoqevbsyfe///0Dtg8YMICtW7fuW3/55Ze56qqr9q2/8MILjB07luOPP55Ro0bx3e9+txmfLnkK\nCGDn4mAEU+4IBYSI7J/ue9GiRdxwww3cfPPN+9Zjp81oSlMBMXPmTEaOHMmTTz6Z9DEXL17Mt771\nLaZNm8bSpUuZP38+hYWFSb++OXRGFg1xFcl4hzPHd0MOce7vxx57jKlTp1JVVcWZZ57J/fffT11d\nHZMnT2bRokW4O1OmTOHII49k0aJFXHPNNXTs2JE5c+YcFC7Tpk3j29/+Nvfeey9z5szh1FNPbfL9\nf/azn/GDH/yA4cOHA8HcTl/72tea/TmSkdYWhJmNN7OVZlZsZrc1sM/VZrbMzJaa2Z9itg8ys7+b\n2fLw+cJ01Zm/PgyIY45J11uISBvw3nvv8eyzz/LWW2+xaNEiampqmD59OvPnz2fz5s28++67vPfe\ne3z+85/nmmuuYdSoUTz55JMJWx67d+/mtdde47LLLsuY6b3jpa0FYWbZwFRgHFAKzDWzGe6+LGaf\nYcDtwFnuXmFmsfNs/wH4D3efZWZdgLp01FleDv32lLCzWz+6dOyYjrcQkcMV9RzfoZdffpm5c+fu\nmzOpsrKSgQMHcskll7By5UpuuukmLr/8ci6++OImjzVjxgzGjRtHfn4+n/nMZxg7diy/+MUvyMrK\nimx673jp7GI6FSh299UAZjYduBKIvZvGV4Cp7l4B4O6bwn1HAjnuPivcvjNdRebnw+UjSsjqou4l\nEWmcu3P99ddzzz33HPTckiVLeOmll5g6dSrPPPMMDz74YKPHmjZtGm+//fa+8wdlZWW8/vrrnH/+\n+fum966/73Si6b2PP/741H64BNLZxdQfWBezXhpuizUcGG5m/zSzt81sfMz2rWb2ZzNbaGY/D1sk\nBzCzKWY2z8zmlZWVHVKRnTtDn23FdDpRQ1xFpHEXXXQRTz31FJs3bwaC0U5r166lrKwMd+czn/kM\nd999NwsWLACga9eu7Nix46DjbN26lbfffpvS0tJ903v/6le/OmB67z/+8Y8A1NTU8MQTT+yb3vvW\nW2/lnnvuobi4GIDa2tp9M7umWtSjmHKAYcB5wCTgd2bWI9x+DnALcApwDPDF+Be7+4PuXuTuRQUF\nBYdWwe7dsGGDTlCLSJNOPPFE7rzzTi666CJOOukkLr74YjZu3Mi6dev4xCc+wahRo5g8eTI//vGP\nAZg8eTJf/vKXDxoe+8wzzzBu3Dhyc3P3bbvqqqt47rnnqK6u5q677mLZsmWcfPLJjBkzhuOOO45J\nkyYBMHr0aH7xi19w9dVXM3LkSE488UQ+/PDDtHzetE33bWZnAHe5+yXh+u0A7v6TmH0eAN5x90fC\n9VeA24Bs4Gfufm64/TrgdHf/ekPvd8jTfZeVwU03wfXXw7hxzX+9iKSFpvtOvUya7nsuMMzMBptZ\nHjARmBG3z3MErQfMrDdB19Lq8LU9zKy+WXABB567SJ2CApg2TeEgIhInbQHh7jXAN4CZwHLgKXdf\namZ3m9mEcLeZQLmZLQNeBf7d3cvdvZage+kVM3sXMOB36apVREQOltYL5dz9ReDFuG13xDx24Nvh\nEv/aWcBJ6axPRDKbu0cyvLMtOpTTCVGfpBYRSSg/P5/y8vJD+mKTA7k75eXl5OfnN+t1mmpDRDLS\ngAEDKC0t5VCHsMuB8vPzGTBgQLNeo4AQkYyUm5vL4MGDoy6jXVMXk4iIJKSAEBGRhBQQIiKSUNqu\npG5pZlYGpOd680PXG9gcdRHN0JrqbU21QuuqtzXVCq2r3kys9Wh3TzhXUZsJiExkZvMauoQ9E7Wm\neltTrdC66m1NtULrqrc11QrqYhIRkQYoIEREJCEFRHo1fseQzNOa6m1NtULrqrc11Qqtq97WVKvO\nQYiISGJqQYiISEIKCBERSUgBkQZmNtDMXjWzZWa21My+GXVNTTGz7PD+389HXUtTzKyHmT1tZivM\nbHl498KMZGY3h/8G3jOzaWbWvOk008zMHjazTWb2Xsy2nmY2y8xWhT+PiLLGWA3U+/Pw38ISM3s2\nvG1x5BLVGvPcd8zMwxulZSwFRHrUAN9x95HA6cDXzWxkxDU15ZsEN3ZqDe4D/ubuI4CTydC6zaw/\ncBNQ5O4nENxKd2K0VR3kUWB83LbbgFfcfRhQfxvgTPEoB9c7CzjB3U8C3gdub+miGvAoB9eKmQ0E\nLgbWtnRBzaWASAN33+DuC8LHOwi+wPpHW1XDzGwAcDnw+6hraYqZdQc+ATwE4O5V7r412qoalQN0\nNLMcoBPwUcT1HMDd/w/YErf5SuCx8PFjwFUtWlQjEtXr7n8P72AJ8DbQvDmt06SB3y3AvcCtQMaP\nEFJApJmZFQKjgXeiraRRvyT4B1sXdSFJGAyUAY+EXWK/N7POUReViLuvB/6L4C/FDcA2d/97tFUl\n5Uh33xA+/hg4Mspimul64KWoi2iImV0JrHf3xVHXkgwFRBqZWRfgGeBb7r496noSMbMrgE3uPj/q\nWpKUA4wBfuPuo4FdZFYXyD5h3/2VBKHWD+hsZtdGW1XzhLcFzvi/dAHM7HsE3btPRF1LImbWCfh/\nwB1N7ZspFBBpYma5BOHwhLv/Oep6GnEWMMHM1gDTgQvM7PFoS2pUKVDq7vUtsqcJAiMTXQR84O5l\n7l4N/Bk4M+KakrHRzPoChD83RVxPk8zsi8AVwOc8cy/uGkLwx8Li8P+3AcACMzsq0qoaoYBIAwvu\nsv4QsNzd/zvqehrj7re7+wB3LyQ4gfoPd8/Yv3Ld/WNgnZkdG266EFgWYUmNWQucbmadwn8TF5Kh\nJ9TjzAC+ED7+AvCXCGtpkpmNJ+gineDuu6OupyHu/q6793H3wvD/t1JgTPhvOiMpINLjLOA6gr/G\nF4XLZVEX1YbcCDxhZkuAUcCPI64nobCV8zSwAHiX4P+3jJpqwcymAbOBY82s1My+BPwUGGdmqwha\nQT+NssZYDdR7P9AVmBX+v/ZApEWGGqi1VdFUGyIikpBaECIikpACQkREElJAiIhIQgoIERFJSAEh\nIiIJKSCk3TKzXjHDkD82s/Ux63lpes8cMzvkuaPM7Nv1M8Ie7rFEmqJhriKAmd0F7HT3/4rbbgT/\nn6Rknqpw0r7N7n5IU1KbWSnBzKVbD/dYIk1RC0IkjpkNDe/l8QSwFOhrZpea2WwzW2BmT9ZPEGhm\np5jZ62Y238xeMrODJrYzsyFm9o6ZvQv8MO6528xsTngvgzti3n+pmU0P73fxlJl1NLObgT7AG2b2\ncswxfmpmi8P6+qTxVyPtjAJCJLERwL3hPT2qCSYEvNDdxwBLgG+aWQeCe1P8q7uPBR4H7klwrF8D\n97n7icTMaxReXT8IOI3givAzzax+rqaRwC/d/ThgD/BVd783fP057n5RuF934HV3P5ngqt3rU/Yb\nkHYvJ+oCRDJUibvPCx+fSfCF/VbQ40Qe8CZwHHA88HK4PZtgfp14ZwCfDB//kf2tiIuBS4GF4XoX\nYDhBCHzg7m+H2x8HphBMyx6v0t3rp7eeD5zTrE8p0ggFhEhiu2IeG8Ed7K6L3cHMRgNL3D2ZL+VE\nJ/sM+JG7PxR33KEJ9m/oZGFVzONa9P+0pJC6mESa9hZwrpkdA2Bmnc1sGMEssv3N7NRwe56ZHZ/g\n9bOBq8PHn4vZPhP4Usz5jAEx9ygebGanhI8/S9BiAdhBMDGdSNopIESa4O4bgS8BT5rZYoLAGO7u\ne4FPA/8dziy7kOB8QrybgJvDffadxHb3Fwlme307PIH9FEE3EwTTgn/bzJYT3Kq0fhbYBwm6tPad\npBZJFw1zFckwYRfT0+4+KupapH1TC0JERBJSC0JERBJSC0JERBJSQIiISEIKCBERSUgBISIiCSkg\nREQkof8P2EVVMZsYDNgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX1U0faDMCy2",
        "colab_type": "code",
        "outputId": "f78b695e-f83b-4ac3-d87a-7a149e6587a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "min_samples_leafs = np.linspace(0.05, 0.3, 5, endpoint=True)\n",
        "train_results = []\n",
        "test_results = []\n",
        "for min_samples_leaf in min_samples_leafs:\n",
        "   dt = DecisionTreeClassifier(max_depth=5.5,min_samples_split=0.67,min_samples_leaf=min_samples_leaf)\n",
        "   dt.fit(X_train_res, y_train_res)\n",
        "   train_pred = dt.predict(X_train)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   train_results.append(roc_auc)\n",
        "   y_pred = dt.predict(X_test)\n",
        "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "   test_results.append(roc_auc)\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "line1, = plt.plot(min_samples_leafs, train_results, 'b', label=\"Train AUC\")\n",
        "line2, = plt.plot(min_samples_leafs, test_results, 'r', label=\"Test AUC\")\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('AUC score')\n",
        "plt.xlabel('min samples leaf')\n",
        "plt.show()\n",
        "## Min_Samples 0.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1eQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1opoDjM9At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf=DecisionTreeClassifier(max_depth=6,min_samples_split=0.625)\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfUCnAtg58Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "datasplit=zmydatatrain[varlist]\n",
        "datasplit1 = datasplit.drop(\"fraud_label\", axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(datasplit1, datasplit['fraud_label'], test_size = 0.20, random_state = 59, stratify = datasplit['fraud_label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AuHH3T657c-",
        "colab_type": "code",
        "outputId": "71162a98-7bcf-4534-e072-1ec1e023ce6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
        "  \n",
        "# import SMOTE module from imblearn library \n",
        "# pip install imblearn (if you don't have imblearn in your system) \n",
        "from imblearn.over_sampling import SMOTE \n",
        "sm = SMOTE(random_state = 2) \n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
        "  \n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
        "  \n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, counts of label '1': 9189\n",
            "Before OverSampling, counts of label '0': 626807 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After OverSampling, the shape of train_X: (1253614, 30)\n",
            "After OverSampling, the shape of train_y: (1253614,) \n",
            "\n",
            "After OverSampling, counts of label '1': 626807\n",
            "After OverSampling, counts of label '0': 626807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_wWY0DcuOpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_sub=X_train_res\n",
        "clf.fit(X_train_res, y_train_res)\n",
        "prediction_train = clf.predict(X_train_sub)\n",
        "matrix = confusion_matrix(y_train_res, prediction_train)\n",
        "train_acc = clf.score(X_train_sub, y_train_res)\n",
        "train_auc = roc_auc_score(y_train_res, prediction_train)\n",
        "train_fdr = matrix[1,1]/sum(y_train_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4EvG_ZnwPBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McCxeLMP8Fyf",
        "colab_type": "code",
        "outputId": "c3030665-1531-46ed-8a76-84fd6d3da3c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "varlist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fulladdress_count1_date',\n",
              " 'fulladdress_count30_date',\n",
              " 'fulladdress_days_since_last_seen',\n",
              " 'fulladdress_nunique1_dob',\n",
              " 'fulladdresshomephone_count30_date',\n",
              " 'fulladdresshomephone_days_since_last_seen',\n",
              " 'namedob_count14_date',\n",
              " 'namedob_count30_date',\n",
              " 'namedob_days_since_last_seen',\n",
              " 'ssn_days_since_last_seen',\n",
              " 'ssndob_count30_date',\n",
              " 'ssndob_days_since_last_seen',\n",
              " 'ssnfname_days_since_last_seen',\n",
              " 'ssnfullname_count30_date',\n",
              " 'ssnfullname_days_since_last_seen',\n",
              " 'ssnlname_count30_date',\n",
              " 'ssnlname_days_since_last_seen',\n",
              " 'ssnnamedob_count30_date',\n",
              " 'ssnnamedob_days_since_last_seen',\n",
              " 'ssnlname_count180_date',\n",
              " 'fulladdresshomephone_count14_date',\n",
              " 'fulladdress_nunique3_ssn',\n",
              " 'address_days_since_last_seen',\n",
              " 'ssnfname_count14_date',\n",
              " 'ssnlname_count14_date',\n",
              " 'ssnfname_count30_date',\n",
              " 'ssnfullname_count180_date',\n",
              " 'ssnfname_count180_date',\n",
              " 'namedob_count180_date',\n",
              " 'ssnnamedob_count180_date',\n",
              " 'fraud_label']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 785
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbYClmQEvI5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_sub = X_test[varlist[:30]]\n",
        "prediction_test = clf.predict_proba(X_test_sub)[:,1]\n",
        "temp=pd.DataFrame(prediction_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emJZy24HvRS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQllA71vwN9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=temp.sort_values(0,ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ60kB1CxJEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testFDRdt=sum(temp[:round(len(temp)*0.03)]['fraud_label']==1)/sum(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl-AV1RAyfcY",
        "colab_type": "code",
        "outputId": "a5dccc3e-2b5e-4256-9422-59f3f1b10967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(f'The testing FDR at 3% is {testFDRdt}.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The testing FDR at 3% is 0.543317370483239.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL02zU8Nv0Ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#matrix = confusion_matrix(y_test, prediction_test)\n",
        "#test_acc = clf.score(X_test_sub, y_test)\n",
        "#test_auc = roc_auc_score(y_test, prediction_test)\n",
        "#test_fdr = matrix[1,1]/sum(y_test)\n",
        "#comparison_df = pd.DataFrame({ \"Accuracy\": [train_acc, test_acc],\n",
        "                                  #\"AUC score\": [train_auc, test_auc],\n",
        "                                  #\"FDR\": [train_fdr, test_fdr]},\n",
        "                                 #index = [\"Training\", \"Testing\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfyABneRx6b2",
        "colab_type": "code",
        "outputId": "e61fe936-7b2b-4e2d-e4dc-fe65855a66d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "prediction_train=clf.predict_proba(X_train)[:,1]\n",
        "temp=pd.DataFrame(prediction_train,y_train)\n",
        "temp.reset_index(inplace=True)\n",
        "temp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fraud_label</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635991</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635992</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635993</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635994</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635995</th>\n",
              "      <td>0</td>\n",
              "      <td>0.327777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>635996 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        fraud_label         0\n",
              "0                 0  0.327777\n",
              "1                 0  0.327777\n",
              "2                 0  0.327777\n",
              "3                 0  0.327777\n",
              "4                 0  0.327777\n",
              "...             ...       ...\n",
              "635991            0  0.327777\n",
              "635992            0  0.327777\n",
              "635993            0  0.327777\n",
              "635994            0  0.327777\n",
              "635995            0  0.327777\n",
              "\n",
              "[635996 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 792
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOnsn72HtY38",
        "colab_type": "code",
        "outputId": "5cbb584b-2e1a-449d-e6ec-457dfe206c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "temp=temp.sort_values(0,ascending=False)\n",
        "temp1=temp[:round(len(temp)*0.03)]\n",
        "trainFDRdt=temp1['fraud_label'].sum()/(temp['fraud_label'].sum())\n",
        "print(f'The training FDR at 3% is {trainFDRdt}.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training FDR at 3% is 0.5361845685058222.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj5eN4Kl11dK",
        "colab_type": "code",
        "outputId": "6d23cdc2-3381-4f85-d1ed-4a521efb99f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "temp1['fraud_label'].sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 794
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE64KLpr1INo",
        "colab_type": "code",
        "outputId": "48b3d54e-826b-4f12-f04f-335c9a7640e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "temp['fraud_label'].sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 795
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrSlVwEk3IWl",
        "colab_type": "text"
      },
      "source": [
        "##### Testing with OOT Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qquh4Onr3IAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatest=zmydatatest[varlist[:30]]\n",
        "ztestfraud=zmydatatest['fraud_label']\n",
        "predict=clf.predict_proba(datatest)[:,1]\n",
        "temp=pd.DataFrame(predict,ztestfraud).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPurNfV73OIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=temp.sort_values(0,ascending=False)\n",
        "temp=temp[:round(len(temp)*0.03)]\n",
        "ootfdrdt=temp['fraud_label'].sum()/zmydatatest['fraud_label'].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-tWhJcy39wS",
        "colab_type": "code",
        "outputId": "a3a0f7f5-4df3-42d3-992e-5c64eefb038a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "print(f'The train FDR for decision tree is: {round(trainFDRdt*100,4)}%\\n\\\n",
        "The test FDR for decision tree is: {round(testFDRdt*100,4)}%\\n\\\n",
        "The oot FDR for decision tree is: {round(ootfdrdt*100,4)}%.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The train FDR for decision tree is: 53.6185%\n",
            "The test FDR for decision tree is: 54.3317%\n",
            "The oot FDR for decision tree is: 50.5029%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSQ_ZaxI4lO8",
        "colab_type": "code",
        "outputId": "d32d2c96-efed-4699-fcf2-461858235b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(varlist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 799
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj0dQGmMmHC_",
        "colab_type": "text"
      },
      "source": [
        "#### NeuroNet (1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xv5EmGDmIkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9vqgy95Hr3F",
        "colab_type": "code",
        "outputId": "de9559d4-c84c-4466-f7c7-56bc66af194b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "varlist=varall2[:30]['variable'].to_list()\n",
        "varlist.append('fraud_label')\n",
        "varlist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fulladdress_count1_date',\n",
              " 'fulladdress_count30_date',\n",
              " 'fulladdress_days_since_last_seen',\n",
              " 'fulladdress_nunique1_dob',\n",
              " 'fulladdresshomephone_count30_date',\n",
              " 'fulladdresshomephone_days_since_last_seen',\n",
              " 'namedob_count14_date',\n",
              " 'namedob_count30_date',\n",
              " 'namedob_days_since_last_seen',\n",
              " 'ssn_days_since_last_seen',\n",
              " 'ssndob_count30_date',\n",
              " 'ssndob_days_since_last_seen',\n",
              " 'ssnfname_days_since_last_seen',\n",
              " 'ssnfullname_count30_date',\n",
              " 'ssnfullname_days_since_last_seen',\n",
              " 'ssnlname_count30_date',\n",
              " 'ssnlname_days_since_last_seen',\n",
              " 'ssnnamedob_count30_date',\n",
              " 'ssnnamedob_days_since_last_seen',\n",
              " 'ssnlname_count180_date',\n",
              " 'fulladdresshomephone_count14_date',\n",
              " 'fulladdress_nunique3_ssn',\n",
              " 'address_days_since_last_seen',\n",
              " 'ssnfname_count14_date',\n",
              " 'ssnlname_count14_date',\n",
              " 'ssnfname_count30_date',\n",
              " 'ssnfullname_count180_date',\n",
              " 'ssnfname_count180_date',\n",
              " 'namedob_count180_date',\n",
              " 'ssnnamedob_count180_date',\n",
              " 'fraud_label']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvOUN0MImoGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varlist=varall2[:30]['variable'].to_list()\n",
        "varlistcopy=varall2[:30]['variable'].to_list()\n",
        "#varlistcopy=varlist.copy()\n",
        "#varlist.append('fraud_label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn57z5TYgzZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varlist.append('fraud_label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfEM2t4y29F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'solver': ['lbfgs'], 'max_iter': [500,1000,1500], 'alpha': 10.0 ** -np.arange(1, 7), 'hidden_layer_sizes':np.arange(5, 12), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
        "clf_grid_hair_soul = GridSearchCV(neural_network.MLPClassifier(), parameters, n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho9wvwN-mTBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(15,15,15), max_iter = 1500,solver='sgd',learning_rate_init=0.001,random_state=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RwkPZWgmfrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "datasplit=zmydatatrain[varlist]\n",
        "datasplit1 = datasplit.drop(\"fraud_label\", axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(datasplit1, datasplit['fraud_label'], test_size = 0.20, random_state = 10, stratify = datasplit['fraud_label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anBA6zEImf1I",
        "colab_type": "code",
        "outputId": "23326198-c525-416b-cc3b-7f6a692e76b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
        "  \n",
        "# import SMOTE module from imblearn library \n",
        "# pip install imblearn (if you don't have imblearn in your system) \n",
        "from imblearn.over_sampling import SMOTE \n",
        "sm = SMOTE(random_state = 2) \n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
        "  \n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
        "  \n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, counts of label '1': 9189\n",
            "Before OverSampling, counts of label '0': 626807 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After OverSampling, the shape of train_X: (1253614, 30)\n",
            "After OverSampling, the shape of train_y: (1253614,) \n",
            "\n",
            "After OverSampling, counts of label '1': 626807\n",
            "After OverSampling, counts of label '0': 626807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWk2c1HImu6E",
        "colab_type": "code",
        "outputId": "ee397506-ee3f-4ba4-fd81-5fd8edd18297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "X_train_sub = X_train_res\n",
        "clf.fit(X_train_sub, y_train_res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(15, 15, 15), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=8, shuffle=True, solver='sgd',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 436
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43scJAQzm0Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_train = clf.predict(X_train_sub)\n",
        "matrix = confusion_matrix(y_train_res, prediction_train)\n",
        "train_acc = clf.score(X_train_sub, y_train_res)\n",
        "train_auc = roc_auc_score(y_train_res, prediction_train)\n",
        "train_fdr = matrix[1,1]/sum(y_train_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enwaZUclc6q3",
        "colab_type": "code",
        "outputId": "d4ec6576-2233-4008-fd32-340f11ed0289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(varlist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 438
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjv18u_xnGzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n=30\n",
        "temp=pd.DataFrame()\n",
        "X_test_sub = X_test[varlist[:n]]\n",
        "prediction_test = clf.predict_proba(X_test_sub)[:,1]\n",
        "temp=pd.DataFrame(prediction_test,y_test)\n",
        "temp.reset_index(inplace=True)\n",
        "temp=temp.sort_values(0,ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPc15_fanRHd",
        "colab_type": "code",
        "outputId": "cb2ba71c-5191-4b86-bb36-94f8c93094f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "testFDRnn=sum(temp[:round(len(temp)*0.03)]['fraud_label']==1)/sum(y_test)\n",
        "print(f'The testing FDR at 3% is {testFDRnn}.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The testing FDR at 3% is 0.5454941227688289.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_IS5alYoqSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_train=clf.predict_proba(X_train)[:,1]\n",
        "temp=pd.DataFrame(prediction_train,y_train)\n",
        "temp.reset_index(inplace=True)\n",
        "temp=temp.sort_values(0,ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC1ErPqoaYcE",
        "colab_type": "code",
        "outputId": "d12fb99b-421b-4f18-e950-9020eaea8eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "temp['fraud_label'].sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvHwziLbqO9i",
        "colab_type": "code",
        "outputId": "573beb4f-a71b-4176-c387-fbe4affbd82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\n",
        "temp1=temp[:round(len(temp)*0.03)]\n",
        "trainFDRnn=temp1['fraud_label'].sum()/(temp['fraud_label'].sum())\n",
        "print(f'The training FDR at 3% is {trainFDRnn}.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training FDR at 3% is 0.5430405920121885.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCjIOM0mqQpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatest=zmydatatest[varlistcopy]\n",
        "ztestfraud=zmydatatest['fraud_label']\n",
        "predict=clf.predict_proba(datatest)[:,1]\n",
        "temp=pd.DataFrame(predict,ztestfraud).reset_index()\n",
        "temp=temp.sort_values(0,ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNCJCGxGqhrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "temp=temp[:round(len(temp)*0.03)]\n",
        "ootfdrnn=temp['fraud_label'].sum()/zmydatatest['fraud_label'].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3jHEjPhqjxw",
        "colab_type": "code",
        "outputId": "32c82797-4484-4c13-da5d-209d84d2f644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "print(f'The train FDR for decision tree is: {round(trainFDRnn*100,4)}%\\n\\\n",
        "The test FDR for decision tree is: {round(testFDRnn*100,4)}%\\n\\\n",
        "The oot FDR for decision tree is: {round(ootfdrnn*100,4)}%.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The train FDR for decision tree is: 54.3041%\n",
            "The test FDR for decision tree is: 54.5494%\n",
            "The oot FDR for decision tree is: 52.7661%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cnNQWatSw1B",
        "colab_type": "code",
        "outputId": "e8cd3088-0346-4052-b212-ed834c36d873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import numpy as np\n",
        "int(len(X_train)*0.03)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19079"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 447
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34WOmMycUjKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slicer=list(range(0,34964,1665))\n",
        "final=[]\n",
        "for i in range(1,len(slicer)):\n",
        "  begin=slicer[i-1]\n",
        "  end=slicer[i]\n",
        "  result=sum(temp[begin:end]['fraud_label'])\n",
        "  final.append([slicer[i],result])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbNyzor2Wo7z",
        "colab_type": "code",
        "outputId": "6a1be969-542d-49bd-9f12-47f10bdfc2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1665, 1172],\n",
              " [3330, 71],\n",
              " [4995, 16],\n",
              " [6660, 0],\n",
              " [8325, 0],\n",
              " [9990, 0],\n",
              " [11655, 0],\n",
              " [13320, 0],\n",
              " [14985, 0],\n",
              " [16650, 0],\n",
              " [18315, 0],\n",
              " [19980, 0],\n",
              " [21645, 0],\n",
              " [23310, 0],\n",
              " [24975, 0],\n",
              " [26640, 0],\n",
              " [28305, 0],\n",
              " [29970, 0],\n",
              " [31635, 0],\n",
              " [33300, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 449
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOl-zRCqXRzr",
        "colab_type": "code",
        "outputId": "7bdd90bc-723c-4339-e7cb-5af41faee27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "temp['fraud_label'].sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 450
        }
      ]
    }
  ]
}